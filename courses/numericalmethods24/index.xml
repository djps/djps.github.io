<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>JTMS-MAT-13: Numerical Methods | David Sinden</title>
    <link>https://djps.github.io/courses/numericalmethods24/</link>
      <atom:link href="https://djps.github.io/courses/numericalmethods24/index.xml" rel="self" type="application/rss+xml" />
    <description>JTMS-MAT-13: Numerical Methods</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Tue, 14 Nov 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://djps.github.io/media/logo_hud7cfbe45e4df55bd5c7c181ea654d8f2_56982_300x300_fit_lanczos_3.png</url>
      <title>JTMS-MAT-13: Numerical Methods</title>
      <link>https://djps.github.io/courses/numericalmethods24/</link>
    </image>
    
    <item>
      <title>Taylor Series</title>
      <link>https://djps.github.io/courses/numericalmethods24/part1/taylor/</link>
      <pubDate>Thu, 07 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://djps.github.io/courses/numericalmethods24/part1/taylor/</guid>
      <description>&lt;!--
&lt;p style=&#34;font-size: 14px; letter-spacing: 0.03em; color: rgb(0,0,0,0.54); border-top: 1px solid #e8e8e8; margin-top: 30px; padding-top: 10px; border-bottom: 1px solid #e8e8e8; margin-bottom: 30px; padding-bottom: 10px;&#34;&gt; &lt;span style=&#34;font-weight: 700;&#34;&gt; David Sinden &lt;/span&gt; &amp;middot;
&lt;i class=&#34;far fa-calendar&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; March 11, 2022 &amp;middot;
&lt;i class=&#34;far fa-clock&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; 45 minute read &lt;/p&gt;


&lt;p style=&#34;font-size: 14px; letter-spacing: 0.03em; color: rgb(0,0,0,0.54);&#34;&gt; &lt;span style=&#34;font-weight: 700;&#34;&gt; David Sinden &lt;/span&gt; &amp;middot;
&lt;i class=&#34;far fa-calendar&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; December 07, 2023 &amp;middot;
&lt;i class=&#34;far fa-clock&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; 15 minute read &lt;/p&gt;
--&gt;
&lt;p&gt;The Taylor series, or Taylor expansion of a function, is defined as&lt;/p&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Taylor Series&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;For a function $f : \mathbb{R} \mapsto \mathbb{R}$ which is infinitely differentiable at a point $c$, the Taylor series of $f(c)$ is given by
&lt;/p&gt;
$$
\begin{equation*}
\sum\limits_{k=0}^{\infty} \dfrac{ f^{(k)} \left( c \right) }{k!} \left( x - c \right)^{k}.
\end{equation*}
$$&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;p&gt;This is a power series, which is convergent for some radius.&lt;/p&gt;
&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;Taylor&amp;#39;s Theorem&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;For a function $f \in C^{n+1}\left([a, b]\right)$, i.e. $f$ is $(n+1)$-times continuously differentiable in the interval $[a, b]$, then for some $c$ in the interval, the function can be written as
&lt;/p&gt;
$$
\begin{equation*}
f\left( x \right) = \sum\limits_{k=0}^{n} \dfrac{f^{(k)} \left(c\right) }{k!} \left( x- c \right)^{k} + \dfrac{f^{(n+1)} \left( \xi \right) }{\left( n + 1 \right)!} \left( x - c \right)^{n+1}
\end{equation*}
$$
&lt;p&gt;
for some value $\xi \in \left[ a, b \right]$ where
&lt;/p&gt;
$$
\begin{equation*}
\lim\limits_{\xi \rightarrow c} \dfrac{ f^{(n+1)} \left( \xi \right) }{ \left( n + 1 \right)!} \left( x - c \right)^{n+1} = 0.
\end{equation*}
$$
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Example open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Example:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;An &lt;code&gt;.ipynb&lt;/code&gt; notebook with an example of the Taylor series for $\sin\left(x\right)$ can be accessed online 
.&lt;/p&gt;
&lt;p&gt;It can be downloaded from 
 as a python file or downloaded as a notebook from 
.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;Rolle&amp;#39;s Theorem&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;If a real-valued function $f$ is continuous on a proper closed interval $[a, b]$, differentiable on the open interval $(a, b)$, and has ${f (a) = f (b)}$, then there exists at least one $c$ in the open interval $(a, b)$ such that
&lt;/p&gt;
$$
f^\prime (c) = 0.
$$&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;Mean Value Theorem&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;The theorem states that if $f$ is a continuous function on the closed interval $[a ,b]$ and differentiable on the open interval $(a, b)$, then there exists a point ${c \in (a, b)}$ such that the tangent at $c$ is parallel to the secant line through the endpoints ${\big(a, f(a) \big)}$ and ${\big(b, f(b) \big)}$, that is,
&lt;/p&gt;
$$
f^\prime (c) = \dfrac{f(b) - f(a)}{b - a}.
$$&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



</description>
    </item>
    
    <item>
      <title>Number Representations</title>
      <link>https://djps.github.io/courses/numericalmethods24/part1/number-representations/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://djps.github.io/courses/numericalmethods24/part1/number-representations/</guid>
      <description>&lt;style&gt;
mjx-container {
  display: inline-block;
}
mjx-assistive-mml {
  right: 0px;
  bottom: 0px;
}
&lt;/style&gt;
&lt;!--
&lt;p style=&#34;font-size: 14px; letter-spacing: 0.03em; color: rgb(0,0,0,0.54); border-top: 1px solid #e8e8e8; margin-top: 30px; padding-top: 10px; border-bottom: 1px solid #e8e8e8; margin-bottom: 30px; padding-bottom: 10px;&#34;&gt; &lt;span style=&#34;font-weight: 700;&#34;&gt; David Sinden &lt;/span&gt; &amp;middot;
&lt;i class=&#34;far fa-calendar&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; March 11, 2022 &amp;middot;
&lt;i class=&#34;far fa-clock&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; 45 minute read &lt;/p&gt;


&lt;p style=&#34;font-size: 14px; letter-spacing: 0.03em; color: rgb(0,0,0,0.54);&#34;&gt; &lt;span style=&#34;font-weight: 700;&#34;&gt; David Sinden &lt;/span&gt; &amp;middot;
&lt;i class=&#34;far fa-calendar&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; January 05, 2024 &amp;middot;
&lt;i class=&#34;far fa-clock&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; 25 minute read &lt;/p&gt;
--&gt;
&lt;h2 id=&#34;errors&#34;&gt;Errors&lt;/h2&gt;
&lt;p&gt;There are many different sources of errors which can affect numerical methods, such as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Errors in data&lt;/li&gt;
&lt;li&gt;Round-off errors&lt;/li&gt;
&lt;li&gt;Truncation errors&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Absolute and Relative Errors&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Let $\tilde{a}$ be an approximation to $a$, then the &lt;strong&gt;absolute error&lt;/strong&gt; is given by $\left| {\tilde{a}-a} \right|$.&lt;/p&gt;
&lt;p&gt;If ${\left| a \ne 0\right|}$, the &lt;strong&gt;relative error&lt;/strong&gt; is given by $\left| \dfrac{\tilde{a}-a}{a} \right|$ and the error bound is the magnitude of the admissible error.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;For both addition and subtraction the bounds for the &lt;em&gt;absolute error&lt;/em&gt; are added.&lt;/p&gt;
&lt;p&gt;In division and multiplication the bounds for the &lt;em&gt;relative errors&lt;/em&gt; are added.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Linear Sensitivity to Uncertainties&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;If $y(x)$ is a smooth function, i.e. is differentiable, then $\left\| y^{\prime} \right\|$ can be interpreted as the &lt;strong&gt;linear sensitivity&lt;/strong&gt; of $y(x)$ to uncertainties in $x$.&lt;/p&gt;
&lt;p&gt;For functions of several variables, i.e. $f : \mathbb{R}^n \rightarrow \mathbb{R}$, then
&lt;/p&gt;
$$
\left\| \Delta y \right\| \le \sum\limits_{i=1}^{n}\left\| \dfrac{\partial y}{\partial x_i} \right\|\left\| \Delta x_i \right\|
$$
&lt;p&gt;
where
$\left\| \Delta x_i \right\| = \tilde{x}_i - x_i$ for an approximation $\tilde{x}_i$, thus  ${\left\| \Delta y_i \right\| = \tilde{y}_i - y_i = f \left( \tilde{x}_i \right) - \left( x_i \right)}$.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Example open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Example:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;An &lt;code&gt;.ipynb&lt;/code&gt; notebook with an example of errors and number representations can be accessed online 
.&lt;/p&gt;
&lt;p&gt;It can be downloaded from 
 as a python file or downloaded as a notebook from 
.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;h2 id=&#34;number-representations&#34;&gt;Number Representations&lt;/h2&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Base Representation&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Let $b \in \mathbb{N} \backslash \lbrace 1 \rbrace$. Every integer $x \in \mathbb{N}_0$
can be written as a unique expansion with respect to base $b$ as
&lt;/p&gt;
$$
\begin{equation*}
\left(x\right)_b = a_0 b^0 + a_1 b^1 + \ldots + a_n b^n = \sum \limits_{i=0}^{n} a_i b^i
\end{equation*}
$$
&lt;p&gt;
A number can be written in a nested form:&lt;/p&gt;
$$
\begin{align*}
\left(x\right)\_b &amp; = a_0 b^0 + a_1 b^1 + \ldots + a_n b^n \\\
 &amp; = a_0 + b\left( a_1 + b\left( a_2 + b\left( a_3 + \ldots + b a_n\right) \right. \ldots  \right)
\end{align*}
$$
&lt;p&gt;with $a_i \in \mathbb{N}_0$ and $a_i &lt; b$, i.e. ${a_i \in \lbrace 0, \ldots, b-1 \rbrace }$.&lt;/p&gt;
&lt;p&gt;For a real number, ${x \in \mathbb{R}}$, write&lt;/p&gt;
$$
\begin{align*}
x &amp; = \sum \limits_{i=0}^{n} a_i b^i + \sum \limits_{i=1}^{\infty} \alpha_i b^{-i} \\\
 &amp; = a_n  \ldots a_0 \cdot \alpha_1 \alpha_2 \ldots
\end{align*}
$$
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Algorithm open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Algorithm:	&lt;em&gt;Euclid&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Euclid&amp;rsquo;s algorithm can convert number $x$ in base 10, i.e.
$\left(x \right)_{10}$
into another base, $b$, i.e. $\left(x \right)_{b}$.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Input $\left(x \right)_{10}$&lt;/li&gt;
&lt;li&gt;Determine the smallest integer $n$ such that ${x &lt; b^{n+1}}$&lt;/li&gt;
&lt;li&gt;Let $y=x$. Then for $i=n, \ldots, 0$
$$
      \begin{array}{rcl}
      a_i &amp; = &amp; y \text{ div } b^i \\\
      y &amp; = &amp; y \text{ mod } b^i
      \end{array}
      $$
which at each steps provides an $a_i$ and updates $y$.&lt;/li&gt;
&lt;li&gt;Output as $\left(x \right)\_{b} = a_n a_{n-1} \cdots a_0$&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Algorithm open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Algorithm:	&lt;em&gt;Horner&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;ol&gt;
&lt;li&gt;Input $\left(x \right)_{10}$&lt;/li&gt;
&lt;li&gt;Set $i=0$&lt;/li&gt;
&lt;li&gt;Let $y=x$. Then while $y&gt;0$
$$
      \begin{array}{rcl}
      a_i &amp; = &amp; y \text{ mod } b \\\
      y &amp; = &amp; y \text{ div } b \\\
      i &amp; = &amp; i+1
      \end{array}
      $$
which at each steps provides an $a_i$ and updates $y$.&lt;/li&gt;
&lt;li&gt;Output as $\left(x \right)_{b} = a_n a_{n-1} \cdots a_0$&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Floating Point Representations&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;A number may be represented as
&lt;/p&gt;
$$
x = \sigma \times f \times b^{t-p}
$$
&lt;p&gt;
where $\sigma$ is the sign of the number, i.e. $\pm 1$, $f$ is the mantissa, $b$ is the base, $t$ is the shifted exponent (where $p$ is the shift required to determine the actual exponent.)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Normalized&lt;/em&gt; floating point representations with respect to some base $b$, may store a number $x$ as
&lt;/p&gt;
$$x= \pm 0 \cdot a_1 \ldots a_k \times b^n$$
&lt;p&gt;
where the $a_i \in \lbrace 0, 1, \ldots b-1 \rbrace$ are called the &lt;strong&gt;digits&lt;/strong&gt;, $k$ is the &lt;strong&gt;precision&lt;/strong&gt; and $n$ is the &lt;strong&gt;exponent&lt;/strong&gt;. The set $a_1, \ldots, a_k$ is called the &lt;strong&gt;mantissa&lt;/strong&gt;. Impose that $a_1 \ne 0$, it makes the representation unique.&lt;/p&gt;
&lt;p&gt;Alternative conventions may express $x= \pm  a_1 \cdot a_2 \ldots a_{k-1} \times b^n$, with $a_1 \ne 0$. Normalization refers to specifying the digits before the decimal place.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Let $x$ and $y$ be two normalized floating point numbers with ${x &gt; y &gt; 0}$ and base ${b=2}$. If there exists integers $p$ and ${q \in \mathbb{N}_0}$ such that
&lt;/p&gt;
$$2^{-p} \leq 1 - \dfrac{y}{x} \leq 2^{-q}$$
&lt;p&gt;
then, at most $p$ and at least $q$ significant bits (i.e. significant figures written in base 2) are lost during subtraction.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



</description>
    </item>
    
    <item>
      <title>Linear Equations</title>
      <link>https://djps.github.io/courses/numericalmethods24/part1/linear-equations/</link>
      <pubDate>Mon, 20 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://djps.github.io/courses/numericalmethods24/part1/linear-equations/</guid>
      <description>&lt;style&gt;
mjx-container {
  display: inline-block;
}
mjx-assistive-mml {
  right: 0px;
  bottom: 0px;
}
&lt;/style&gt;
&lt;!--
&lt;p style=&#34;font-size: 14px; letter-spacing: 0.03em; color: rgb(0,0,0,0.54);&#34;&gt; &lt;span style=&#34;font-weight: 700;&#34;&gt; David Sinden &lt;/span&gt; &amp;middot;
&lt;i class=&#34;far fa-calendar&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; April 45, 2024 &amp;middot;
&lt;i class=&#34;far fa-clock&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; 60 minute read &lt;/p&gt;
--&gt;
&lt;h2 id=&#34;linear-equations&#34;&gt;Linear Equations&lt;/h2&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Systems of Linear Equations&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;A system of linear equations (or linear system) is a collection of one or more linear equations involving the same variables. If there are $m$ equations with $n$ unknown variables to solve for&lt;/p&gt;
$$
\begin{align*}
a_{1,1} x_1 + a_{1,2} x_2 + \ldots + a_{1,n} x_n &amp; = b_1 \\
a_{2,1} x_1 + a_{2,2} x_2 + \cdots + a_{2,n} x_n &amp; = b_2 \\
\vdots &amp;  \\
a_{m,1} x_1 + a_{m,2} x_2 + \cdots + a_{m,n} x_n &amp; = b_m.
\end{align*}
$$
&lt;p&gt;The system of linear equations can be written in matrix form ${Ax=b}$, where
&lt;/p&gt;
$$
A = \left(
  \begin{array}{cccc}
  a_{1,1} &amp; a_{1,2} &amp; \cdots &amp; a_{1,n} \\
  a_{2,1} &amp; a_{2,2} &amp; \cdots &amp; a_{2,n} \\
  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
  a_{m,1} &amp; a_{m,2} &amp; \cdots &amp; a_{m,n}
  \end{array}
  \right), \quad x = \left(
    \begin{array}{c}
    x_1 \\\
    x_2 \\\
    \vdots \\\
    x_n
    \end{array}
    \right), \quad b = \left(
      \begin{array}{c}
      b_1 \\
      b_2 \\
      \vdots \\
      b_m
      \end{array}
      \right),
$$
&lt;p&gt;
so that $A \in \mathbb{R}^{m \times n}$, $x \in \mathbb{R}^n$ and $b \in \mathbb{R}^m$.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Banded Systems&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;A &lt;strong&gt;banded&lt;/strong&gt; matrix is a matrix whose non-zero entries are confined to a diagonal band, comprising the main diagonal and zero or more diagonals on either side.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Symmetric Matrices&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;A square matrix $A$ is &lt;strong&gt;symmetric&lt;/strong&gt; if ${A=A^T}$, that is, $a_{i,j}=a_{j,i}$ for all indices $i$ and $j$.&lt;/p&gt;
&lt;p&gt;A square matrix is said to be &lt;strong&gt;Hermitian&lt;/strong&gt; if the matrix is equal to its conjugate transpose, i.e. $a_{i,j}=\overline{a_{j,i}}$ for all indices $i$ and $j$. A Hermitian matrix is written as $A^H$.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Positive Definite Matrices&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;A matrix, $M$, is said to be &lt;strong&gt;positive definite&lt;/strong&gt; if it is symmetric (or Hermitian) and all its eigenvalues are real and positive.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Nonsingular Matrices&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;A matrix is &lt;strong&gt;non-singular&lt;/strong&gt; or &lt;strong&gt;invertible&lt;/strong&gt; if there exists a matrix $A^{-1}$ such that ${A^{-1}A = A A^{-1} = I,}$ where $I$ is the identity matrix.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Note open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m16.862 4.487l1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L6.832 19.82a4.5 4.5 0 0 1-1.897 1.13l-2.685.8l.8-2.685a4.5 4.5 0 0 1 1.13-1.897zm0 0L19.5 7.125&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Note:	&lt;em&gt;Properties of Nonsingular Matrices&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;For a nonsingular matrix, the following all hold:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nonsingular matrix has full rank&lt;/li&gt;
&lt;li&gt;A square matrix is nonsingular if and only if the determinant of the matrix is non-zero.&lt;/li&gt;
&lt;li&gt;If a matrix is singular, both versions of Gaussian elimination will fail due to division by zero, yielding a floating exception error.&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;If $\tilde{x}$ is an approximate solution to the linear problem ${Ax=b}$, then the &lt;strong&gt;residual&lt;/strong&gt; is defined as ${r = A \tilde{x}-b}$.&lt;/p&gt;
&lt;!-- If $\left| r \right|$ is large due to rounding, the matrix is said to be **ill-conditioned**. --&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;h3 id=&#34;direct-methods&#34;&gt;Direct Methods&lt;/h3&gt;
&lt;div class=&#34;details admonition Algorithm open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Algorithm:	&lt;em&gt;Gaussian Elimination&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Gaussian elimination is a method to solve systems of linear equations based on forward elimination (a series of row-wise operations) to convert the matrix, $A$, to upper triangular form (echelon form), and then back substitution to solve the system. The row operations are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;row swapping&lt;/li&gt;
&lt;li&gt;row scaling, i.e. multiplying by a non-zero scalar&lt;/li&gt;
&lt;li&gt;row addition, i.e. adding a multiple of one row to another&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Forward elimination is written as&lt;/p&gt;
&lt;p&gt;&lt;small&gt;1 &lt;/small&gt; For $k=1$ to $n-1$: &lt;br&gt;
&lt;small&gt;2 &lt;/small&gt; $\hspace{2cm}$ For $i = k + 1$ to $n$: &lt;br&gt;
&lt;small&gt;3 &lt;/small&gt; $\hspace{4cm}$ For $j = k$ to $n$: &lt;br&gt;
&lt;small&gt;4 &lt;/small&gt; $\hspace{6cm}  a_{i,j} = a_{i,j} - \dfrac{a_{i,k}}{a_{k,k}} a_{k,j}$ &lt;br&gt;
&lt;small&gt;5 &lt;/small&gt; $\hspace{4cm}$ End &lt;br&gt;
&lt;small&gt;6 &lt;/small&gt; $\hspace{2cm} b_{i} = b_{i} - \dfrac{a_{i,k}}{a_{k,k}} b_{k}$ &lt;br&gt;
&lt;small&gt;7 &lt;/small&gt; End &lt;br&gt;&lt;/p&gt;
&lt;p&gt;Then back substitute, starting with the last unknown first:&lt;/p&gt;
&lt;p&gt;&lt;small&gt;8 &lt;/small&gt; Set $x_n = \dfrac{b_n}{a_{n,n}}$ &lt;br&gt;
&lt;small&gt;9 &lt;/small&gt; For $i$ =$n-1$ to $1$: &lt;br&gt;
&lt;small&gt;10&lt;/small&gt; $\hspace{2cm} y = b_i$ &lt;br&gt;
&lt;small&gt;11&lt;/small&gt; $\hspace{2cm}$ For $j = n$ to $i+1$: &lt;br&gt;
&lt;small&gt;12&lt;/small&gt; $\hspace{4cm} y = y - a_{i,j} x_j$ &lt;br&gt;
&lt;small&gt;13&lt;/small&gt; $\hspace{2cm}$ End &lt;br&gt;
&lt;small&gt;14&lt;/small&gt; $\hspace{2cm} x_i = \dfrac{y}{a_{i,i}}$ &lt;br&gt;
&lt;small&gt;15&lt;/small&gt; End&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Algorithm open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Algorithm:	&lt;em&gt;Gaussian Elimination with Scaled Partial Pivoting&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;A pivot element is the element of a matrix, $A$, which is selected to do certain calculations first. Pivoting helps reduce errors due to rounding.&lt;/p&gt;
&lt;p&gt;&lt;small&gt;1 &lt;/small&gt; Find maximal absolute values vector $s$ with entries $s_i= \max_{j=1,\ldots,n}\left| a_{i,j}\right|$ &lt;br&gt;
&lt;small&gt;2 &lt;/small&gt; For $k=1$ to $n-1$: &lt;br&gt;
&lt;small&gt;3 &lt;/small&gt; $\hspace{2cm}$ For $i = k$ to $n$: &lt;br&gt;
&lt;small&gt;4 &lt;/small&gt; $\hspace{4cm}$ Compute $\left| \dfrac{a_{i,k}}{s_i} \right|$ &lt;br&gt;
&lt;small&gt;5 &lt;/small&gt; $\hspace{2cm}$ End &lt;br&gt;
&lt;small&gt;6 &lt;/small&gt; $\hspace{2cm}$ Find row with largest relative pivot element, denote this as row $j$ &lt;br&gt;
&lt;small&gt;7 &lt;/small&gt; $\hspace{2cm}$ Swap rows $k$ and $j$ &lt;br&gt;
&lt;small&gt;8 &lt;/small&gt; $\hspace{2cm}$ Swap entries $k$ and $j$ in vector $s$ &lt;br&gt;
&lt;small&gt;9 &lt;/small&gt; $\hspace{2cm}$ Do forward elimination on row $k$ &lt;br&gt;
&lt;small&gt;10&lt;/small&gt; End &lt;br&gt;&lt;/p&gt;
&lt;p&gt;The matrix will be in row-echelon form, so that back substitution can now be performed.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Upper and Lower Triangular Matrices&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;A square matrix is said to be &lt;strong&gt;lower triangular matrix&lt;/strong&gt; if all the elements above the main diagonal are zero and &lt;strong&gt;upper triangular&lt;/strong&gt; if all the entries below the main diagonal are zero.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;$LU$-Decomposition&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Let ${A \in \mathbb{R}^{n \times n}}$ be invertible. Then there exists a decomposition of $A$ such that ${A=LU}$, where $L$ is a lower triangular matrix and $U$ is an upper triangular matrix, And
&lt;/p&gt;
$$
L = U_1^{-1} U_2^{-1} \cdots U_{n-1}^{-1}
$$
&lt;p&gt;
where each matrix $U_i$ is a matrix which describes the $i^{\text{th}}$ step in forward elimination. The upper triangular matrix $U$ is given by
&lt;/p&gt;
$$
U = U_{n-1} \cdots U_2 U_1 A.
$$
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Cholesky-Decomposition&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;A symmetric, positive definite matrix can be decomposed as $A=\tilde{L}\tilde{L}^T$, where ${\tilde{L} = L D^{1/2}}$, where $D$ is a diagonal matrix whose elements $d_i$ are all positive, so that $D^{1/2}$ has elements $\sqrt{d_i}$.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Algorithm open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Algorithm:	&lt;em&gt;Cholesky Algorithm&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Cholesky&amp;rsquo;s algorithm to compute the entries of the triangular matrix $L$ can be written as&lt;/p&gt;
&lt;p&gt;&lt;small&gt;1 &lt;/small&gt; For $i=1$ to $n$: &lt;br&gt;
&lt;small&gt;2 &lt;/small&gt; $\hspace{2cm}$ For $j = 1$ to $i-1$: &lt;br&gt;
&lt;small&gt;3 &lt;/small&gt; $\hspace{4cm}$ Set $y = a_{i,j}$ &lt;br&gt;
&lt;small&gt;4 &lt;/small&gt; $\hspace{4cm}$ For $k = 1$ to $j-1$: &lt;br&gt;
&lt;small&gt;5 &lt;/small&gt; $\hspace{6cm}$ $y = y - l_{i,k} l_{j,k}$ &lt;br&gt;
&lt;small&gt;6 &lt;/small&gt; $\hspace{4cm}$ End &lt;br&gt;
&lt;small&gt;7 &lt;/small&gt; $\hspace{4cm}$ $l_{i,j} = y / l_{j,j}$ &lt;br&gt;
&lt;small&gt;8 &lt;/small&gt; $\hspace{2cm}$ End &lt;br&gt;
&lt;small&gt;9 &lt;/small&gt; $\hspace{2cm}$ Set $y = a_{i,i}$ &lt;br&gt;
&lt;small&gt;10&lt;/small&gt; $\hspace{2cm}$ For $k= 1$ to $i-1$: &lt;br&gt;
&lt;small&gt;11&lt;/small&gt; $\hspace{4cm}$ $y = y - l_{i,k} l_{i,k}$ &lt;br&gt;
&lt;small&gt;12&lt;/small&gt; $\hspace{2cm}$ End &lt;br&gt;
&lt;small&gt;13&lt;/small&gt; $\hspace{2cm}$ If $y \le 0$: &lt;br&gt;
&lt;small&gt;14&lt;/small&gt; $\hspace{4cm}$ exit as there is no solution &lt;br&gt;
&lt;small&gt;15&lt;/small&gt; $\hspace{2cm}$ Else: &lt;br&gt;
&lt;small&gt;16&lt;/small&gt; $\hspace{4cm}$ $l_{i,i} = \sqrt{y}$ &lt;br&gt;
&lt;small&gt;12&lt;/small&gt; $\hspace{2cm}$ End &lt;br&gt;
&lt;small&gt;17&lt;/small&gt; End &lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;h3 id=&#34;indirect-methods&#34;&gt;Indirect Methods&lt;/h3&gt;
&lt;p&gt;For a non-singular matrix $A$, consider the iterative scheme
&lt;/p&gt;
$$
Q x_{k +1}= \left( Q - A \right) x_{k} + b.
$$
&lt;p&gt;This is equivalent to&lt;/p&gt;
$$
x_{k +1} = \left( I - Q^{-1} A \right) x_{k} + Q^{-1} b.
$$
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Spectral Radius of a Matrix&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;The &lt;a id=&#34;spectral&#34;&gt;&lt;strong&gt;spectral radius&lt;/strong&gt;&lt;/a&gt; of a matrix $A$ is defined as
&lt;/p&gt;
$$
\rho \left( A \right) = \max \left\{  \left\|  \lambda_1 \right\|,  \left\|  \lambda_2 \right\|, \ldots   \left\|  \lambda_n \right\| \right\}
$$
&lt;p&gt;where the $\lambda_i$ are the eigenvalues of the matrix.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;Convergence&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;The iterative scheme converges if and only if the spectral radius of the matrix ${I - Q^{-1} A}$ is less than one, i.e. ${\rho\left( I - Q^{-1} A \right) \lt 1}$.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Richardson Iteration&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Let $Q=I$, then &lt;strong&gt;Richardson iteration&lt;/strong&gt; computes the sequence of vectors&lt;/p&gt;
$$
x_{k +1} = \left(I - A \right) x_{k} + b.
$$
&lt;p&gt;This sequence may converge to $x = A^{-1} b$, depending on $A$.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;modified Richardson iteration&lt;/strong&gt; scales ${Q = \omega I}$, so that
&lt;/p&gt;
$$
x_{k +1}=  x_{k} + \omega \left( b - A x_{k} \right).
$$
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Jacobi Iteration&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;The  &lt;a id=&#34;Jacobi&#34;&gt;&lt;strong&gt;Jacobi iteration&lt;/strong&gt;&lt;/a&gt; scheme has $Q=D$, so
&lt;/p&gt;
$$
x_{k +1} = \left(I - D^{-1} A \right) x_{k} + D^{-1} b.
$$
&lt;p&gt;
where $D$ is the matrix comprised of the diagonal elements of $A$.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Diagonally Dominant Matrices&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;A matrix $A \in \mathbb{R}^{n \times n}$ is said to be &lt;strong&gt;diagonally dominant&lt;/strong&gt; if, for every row, the absolute value of the diagonal element is greater or equal to the sum of the magnitudes of all other elements, i.e.
&lt;/p&gt;
$$
\left\| a_{i,i} \right\| \ge \sum\limits_{\substack{j=1,\newline{}j \neq i}}^n \left\| a_{i,j} \right\| \quad \text{for all } i \in (1,n)
$$&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;Convergence of Jacobi Scheme&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;If the matrix $A$ is diagonally dominant, then the Jacobi scheme converges for any initial guess $x_0$.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Gauss-Seidel Scheme&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Let $Q=L + D$, then the &lt;a id=&#34;GS&#34;&gt;&lt;strong&gt;Gauss-Seidel&lt;/strong&gt;&lt;/a&gt; scheme is given by
&lt;/p&gt;
$$
\begin{equation*}
(D + L) x_{k+1} = -U x_{k} + b
\end{equation*}
$$
&lt;p&gt;
where $L$ is the lower triangular part of $A$, and $D$ is the diagonal matrix of $A$.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;Convergence of Gauss-Seidel Scheme&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;If the matrix $A$ is diagonally dominant, then the Gauss-Seidel scheme converges for any initial guess $x_0$.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Successive Over Relaxation (SOR)&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Let $Q=L + \dfrac{1}{\omega}D$, thus, the method of &lt;a id=&#34;SOR&#34;&gt;&lt;strong&gt;successive over relaxation&lt;/strong&gt;&lt;/a&gt; (SOR) is given by
&lt;/p&gt;
$$
\begin{equation*}
(D + \omega L) x_{k+1} = -\left( \left(\omega - 1 \right)D + \omega U \right) x_{k} + \omega b.
\end{equation*}
$$&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;Convergence of Successive Over Relaxation Scheme&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;Let $A$ be a symmetric matrix with positive entries on the diagonal and let ${\omega \in \left(0,2\right)}$. Then, if and only if $A$ is positive definite will the method of &lt;a href=&#34;#SOR&#34;&gt;successive over relaxation&lt;/a&gt; converge.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;h3 id=&#34;fundamental-theorem-of-numerical-analysis&#34;&gt;Fundamental Theorem of Numerical Analysis&lt;/h3&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Stable&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;A numerical method is said to be &lt;strong&gt;stable&lt;/strong&gt; if and only if any initial error $e_0$ is damped during the iterations, i.e. ${\left\| e_k \right\| &lt; \left\| e_0 \right\| }$.&lt;/p&gt;
&lt;p&gt;Note that $\Vert x \Vert $ is a &lt;em&gt;norm&lt;/em&gt; of a vector, such as ${\Vert x \Vert_2 = \sqrt{x_0^2 + x_1^2 + \ldots x_n^2} }$.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Consistent&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;A numerical method is said to be &lt;strong&gt;consistent&lt;/strong&gt; if any fixed point $x^{\ast}$ of the iteration is a solution to the problem being solved.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;p&gt;For linear systems, a fixed point, $x^{\ast}$, fulfils
&lt;/p&gt;
$$
x^{\ast} = \left( I - Q^{-1} A \right) x^{\ast} + Q^{-1} b \Leftrightarrow A x^{\ast} = b.
$$
&lt;p&gt;If the iterative method for a linear system is stable then&lt;/p&gt;
$$
e_k = \left( I - Q^{-1} A \right)^k e_0,
$$
&lt;p&gt;
so then ${\Vert I - Q^{-1} A \Vert &lt; 1}$ for ${\Vert e_k \Vert &lt; \Vert e_0 \Vert}$.&lt;/p&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Convergent&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;A numerical method is said to be &lt;strong&gt;convergent&lt;/strong&gt; if ${x_k \rightarrow x^{\ast}}$ as ${k \rightarrow \infty}$ where $x^{\ast}$ is the exact solution.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;Fundamental Theorem of Numerical Analysis&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;A numerical method is convergent if and only if it is consistent and stable.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Example open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Example:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;An &lt;code&gt;.ipynb&lt;/code&gt; notebook with an example of iterative solvers for linear systems can be accessed online 
.&lt;/p&gt;
&lt;p&gt;It can be downloaded from 
 as a python file or downloaded as a notebook from 
.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



</description>
    </item>
    
    <item>
      <title>Nonlinear Equations</title>
      <link>https://djps.github.io/courses/numericalmethods24/part1/nonlinear-equations/</link>
      <pubDate>Fri, 17 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://djps.github.io/courses/numericalmethods24/part1/nonlinear-equations/</guid>
      <description>&lt;!--
&lt;p style=&#34;font-size: 14px; letter-spacing: 0.03em; color: rgb(0,0,0,0.54);&#34;&gt; &lt;span style=&#34;font-weight: 700;&#34;&gt; David Sinden &lt;/span&gt; &amp;middot;
&lt;i class=&#34;far fa-calendar&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; March 11, 2024 &amp;middot;
&lt;i class=&#34;far fa-clock&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; 45 minute read &lt;/p&gt;
--&gt;
&lt;h2 id=&#34;root-finding&#34;&gt;Root Finding&lt;/h2&gt;
&lt;h3 id=&#34;bisection-method&#34;&gt;Bisection Method&lt;/h3&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Bisection Method&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;The bisection method, when applied in the interval $\left[a, b\right]$ to a function $f \in C^0 \left( \left[a, b\right] \right)$ with ${f(a)f(b) &lt; 0}$&lt;/p&gt;
&lt;p&gt;Bisect the interval into two subintervals $\left[a, c\right]$ and $\left[c, b\right]$ such that ${a &lt; c &lt; b}$.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If $f(c) = 0$ or is sufficiently close, then $c$ is a root&lt;/li&gt;
&lt;li&gt;Else, if $f(c)f(a) &lt; 0$ continue in the interval $[a, c]$&lt;/li&gt;
&lt;li&gt;Else, if $f(c)f(b) &lt; 0$ continue in the interval $[c, b]$&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;Bisection Method&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;The bisection method, when applied in the interval $[a,b]$ to a function $f \in C^0 \left( \left[a, b\right] \right)$ with ${f(a)f(b) &lt; 0}$ will compute, after $n$ steps, an approximation $c_n$ of the root $r$ with error
&lt;/p&gt;
$$
\left\| r - c_n \right\| \lt \dfrac{b-a}{2n}.
$$&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;h3 id=&#34;newtons-method&#34;&gt;Newton&amp;rsquo;s Method&lt;/h3&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Let a function $f \in C^1 \left( \left[a, b \right] \right)$, then for an initial guess $x_0$, Newton&amp;rsquo;s method is
&lt;/p&gt;
$$
x_{n+1} = x_n - \dfrac{f\left( x_n \right)}{f\left( x_n \right)}.
$$&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;When Newton&amp;rsquo;s method converges, it converges to a root, $r$, of $f$, i.e. ${f\left(r\right)=0}$.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Let $f \in C^1\left( \left[ a, b\right] \right)$, with&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$f(a)f(b) &lt; 0$&lt;/li&gt;
&lt;li&gt;$f^\prime\left(x\right) \ne 0$ for all $x \in \left( a, b \right)$&lt;/li&gt;
&lt;li&gt;$f^{\prime\prime}\left(x\right) $ exists, is continuous and either ${f^{\prime\prime}\left(x\right)  &gt; 0}$ or ${f^{\prime\prime}\left(x\right) &lt; 0}$ for all ${x \in \left( a, b \right)}$.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Then $f(x)=0$ has exactly one root, $r$, in the interval and the sequence generated by Newton iterations converges to the root when the initial guess is chosen according to&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if $f(a) &lt; 0$ and $f^{\prime\prime}(a) &lt; 0$ &lt;em&gt;or&lt;/em&gt; $f(a) &gt; 0$ and $f^{\prime\prime}(a) &gt; 0$ then $x \in \left[ a, r \right]$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if $f(a) &lt; 0$ and $f^{\prime\prime}(a) &gt; 0$ &lt;em&gt;or&lt;/em&gt; $f(a) &gt; 0$ and $f^{\prime\prime}(a) &lt; 0$ then $x \in \left[ r, b \right]$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The iterate in the sequence satisfies
&lt;/p&gt;
$$
\left\| x_n - r\right\| \lt \dfrac{f\left( x_n \right)}{\min \limits_{x \in [a,b]}\left\| f^{\prime}\left( x \right) \right\|}.
$$
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Let $f \in C^1\left( \left[ a, b\right] \right)$, with&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$f(a)f(b) &lt; 0$&lt;/li&gt;
&lt;li&gt;$f^\prime\left( x \right) \ne 0$ for all $x \in \left( a, b \right)$&lt;/li&gt;
&lt;li&gt;$f^{\prime\prime}\left( x \right)$ exists and is continuous, i.e. ${f\left( x \right) \in C^2\left( \left[ a, b \right]\right)}$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Then, if $x_0$ is close enough to the root $r$, Newton&amp;rsquo;s method converges quadratically.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;h3 id=&#34;secant-methods&#34;&gt;Secant Methods&lt;/h3&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;The secant method is defined as
&lt;/p&gt;
$$
x_{n+1} = x_n - f \left( x_n \right) \dfrac{x_{n-1} - x_n}{f \left( x_{n-1} \right) - f \left( x_n \right)}.
$$&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Let $f \in C^2\left( \left[a, b\right] \right)$, and $r \in \left(a,b\right)$ such that ${f\left(r\right) = 0}$ and ${f^{\prime}\left(r\right) \ne 0}$. Furthermore, let
&lt;/p&gt;
$$
x_{n+1} = x_n - f \left( x_n \right) \dfrac{x_{n-1} - x_n}{f \left( x_{n-1} \right) - f \left( x_n \right)}.
$$
&lt;p&gt;
Then there exists a $\delta &gt; 0$ such that when ${\left\|  r - x_0 \right\| &lt; \delta}$ and ${\left\|  r - x_1 \right\| &lt; \delta}$, then the following holds:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;$\lim\limits_{n\rightarrow\infty} \left\|  r - x_n \right\| = 0 \Leftrightarrow \lim\limits_{n\rightarrow\infty} x_n = r$,
and&lt;/li&gt;
&lt;li&gt;$\left\|  r - x_{n+1} \right\| \le \mu \left\|  r - x_{n} \right\|^{\alpha}$ with ${\alpha =\dfrac{1+\sqrt{5}}{2} }.$&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Example open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Example:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;An &lt;code&gt;.ipynb&lt;/code&gt; notebook with an example of iterative solvers for nonlinear systems can be accessed online 
.&lt;/p&gt;
&lt;p&gt;It can be downloaded from 
 as a python file or downloaded as a notebook from 
.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Example open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Example:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;An &lt;code&gt;.ipynb&lt;/code&gt; notebook with an example using the secant method to find a local maxima can be accessed online 
.&lt;/p&gt;
&lt;p&gt;It can be downloaded from 
 as a python file or downloaded as a notebook from 
.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;h2 id=&#34;convergence&#34;&gt;Convergence&lt;/h2&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;If a sequence $x_n$ converges to $r$ as $n \rightarrow \infty$, then it is said to &lt;strong&gt;converge linearly&lt;/strong&gt; if there exists a $\mu \in \left( 0,1\right)$ such that
&lt;/p&gt;
$$
\lim\limits_{n\rightarrow\infty} \dfrac{\left\| x_{n+1} - r \right\|}{\left\| x_{n} - r \right\|} = \mu.
$$
&lt;p&gt;
The sequences converges &lt;strong&gt;super-linearly&lt;/strong&gt; if
&lt;/p&gt;
$$
\lim\limits_{n\rightarrow\infty} \dfrac{\left\| x_{n+1} - r \right\|}{\left\| x_{n} - r \right\|} = 0
$$
&lt;p&gt;
and &lt;strong&gt;sub-linearly&lt;/strong&gt; if
&lt;/p&gt;
$$
\lim\limits_{n\rightarrow\infty} \dfrac{\left\| x_{n+1} - r \right\|}{\left\| x_{n} - r \right\|} = 1.
$$
&lt;p&gt;
More generally, a sequence converges with order $q$ if there exists a ${\mu \gt 0}$ such that
&lt;/p&gt;
$$
\lim\limits_{n\rightarrow\infty} \dfrac{\left\| x_{n+1} - r \right\|}{\left\| x_{n} - r \right\|^q } = \mu
$$
&lt;p&gt;
Thus a sequence is said to converge quadratically when ${q=2}$ and exhibit cubic convergence when $q=3$.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Method&lt;/th&gt;
&lt;th&gt;Regularity&lt;/th&gt;
&lt;th&gt;Proximity to $r$&lt;/th&gt;
&lt;th&gt;Initial points&lt;/th&gt;
&lt;th&gt;Function calls&lt;/th&gt;
&lt;th&gt;Convergence&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Bisection&lt;/td&gt;
&lt;td&gt;$\mathcal{C}^{0}$&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Linear&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Newton&lt;/td&gt;
&lt;td&gt;$\mathcal{C}^{2}$&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;Quadratic&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Secant&lt;/td&gt;
&lt;td&gt;$\mathcal{C}^{2}$&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Superlinear&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;systems-of-nonlinear-equation&#34;&gt;Systems of Nonlinear Equation&lt;/h2&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Multi-dimensional Newton Method&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;For a vector-valued function $f : \mathbb{R}^n \rightarrow \mathbb{R}^n$, which takes as an argument the vector
&lt;/p&gt;
$$
x= \left( x_1, x_2 \ldots, x_n \right) \in \mathbb{R}^n
$$
&lt;p&gt;
the &lt;strong&gt;Jacobian&lt;/strong&gt; matrix is defined as&lt;/p&gt;
$$
\begin{equation*}
J = \left(
  \begin{array}{cccc}
  \dfrac{\partial f_1 }{\partial x_1} &amp; \dfrac{\partial f_1 }{\partial x_2} &amp; \cdots &amp; \dfrac{\partial f_1 }{\partial x_n} \\\
  \dfrac{\partial f_2 }{\partial x_1} &amp; &amp; &amp; \vdots \\\
  \vdots &amp; &amp; &amp; \vdots \\\
  \dfrac{\partial f_n }{\partial x_1} &amp; \dfrac{\partial f_n }{\partial x_2} &amp; \cdots &amp; \dfrac{\partial f_n }{\partial x_n}
  \end{array}
  \right) \in \mathbb{R}^{n \times n}.
  \end{equation*}
$$
&lt;p&gt;If the derivatives are evaluated at the vector $x$, the Jacobian matrix can be parameterised as $J\left(x\right)$. Newton&amp;rsquo;s method can be written as
&lt;/p&gt;
$$
x_{m+1} = x_m - J^{-1} \left( x_m \right) f\left( x_m \right)
$$
&lt;p&gt;
where $J^{-1} \left( x_m \right)$ is the inverse of the Jacobian matrix evaluated at the vector $x_m$, which is the $m$&lt;sub&gt;th&lt;/sub&gt; iterate of the scheme. In practice, as matrix inversion can be computationally expensive, the system
&lt;/p&gt;
$$
J \left( x_m \right) \left( x_{m+1} - x_m \right) = -f \left( x_m \right)
$$
&lt;p&gt;
is solved for the unknown vector $x_{m+1} - x_m$ and then $x_{m+1}$ is found.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



</description>
    </item>
    
    <item>
      <title>Interpolation</title>
      <link>https://djps.github.io/courses/numericalmethods24/part2/interpolation/</link>
      <pubDate>Fri, 17 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://djps.github.io/courses/numericalmethods24/part2/interpolation/</guid>
      <description>&lt;style&gt;
mjx-container {
  display: inline-block;
}
mjx-assistive-mml {
  right: 0px;
  bottom: 0px;
}
&lt;/style&gt;
&lt;p style=&#34;font-size: 14px; letter-spacing: 0.03em; color: rgb(0,0,0,0.54);&#34;&gt; &lt;span style=&#34;font-weight: 700;&#34;&gt; David Sinden &lt;/span&gt; &amp;middot;
&lt;i class=&#34;far fa-calendar&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; March 11, 2024 &amp;middot;
&lt;i class=&#34;far fa-clock&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; 45 minute read &lt;/p&gt;
&lt;h2 id=&#34;interpolation&#34;&gt;Interpolation&lt;/h2&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Interpolating Functions&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Given as set of points $p_0$, $\ldots$, ${p_n \in \mathbb{R}}$ and corresponding nodes $u_0$, $\ldots$, ${u_n \in \mathbb{R}}$, a function ${f : \mathbb{R} \rightarrow \mathbb{R}}$ with ${f(u_i) = p_i}$ is an &lt;strong&gt;interpolating function&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This can be generalised to higher dimensions, i.e. ${f : \mathbb{R} \rightarrow \mathbb{R}^N }$.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Polynomial Interpolation&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;If the interpolating function is a polynomial, it can be written as
&lt;/p&gt;
$$
p\left( u \right) = \sum\limits_{i=0}^{n} \alpha_i \varphi_i \left( u \right)
$$
&lt;p&gt;
so that at every node $u_j$, the polynomial satisfies $p\left( u_j \right) = \sum\limits_{i=0}^{n} \alpha_i \varphi_i \left( u_j \right)$. Thus, solving for all the values of $\alpha$ which fit the interpolating function to the data, leads to a linear system of the form
&lt;/p&gt;
$$\Phi \alpha = p$$
&lt;p&gt;
where $p$ is the vector defined the polynomial evaluated at the node points, i.e. ${p=p\left( u_j \right)}$ and $\Phi$ is the &lt;strong&gt;collocation matrix&lt;/strong&gt;, whose entries are given by the polynomials evaluated at the node points
&lt;/p&gt;
$$
\Phi = \left( \begin{array}{cccc}
  \varphi_0 (u_0) &amp; \varphi_1 (u_0) &amp; \cdots &amp; \varphi_n (u_0) \\\
  \vdots &amp; &amp; &amp; \vdots \\\
  \varphi_0 (u_n) &amp; \cdots &amp; \cdots &amp; \varphi_n (u_n) \end{array} \right).
$$
&lt;p&gt;
Thus, to fit the polynomials to the data $\alpha = \Phi^{-1} p$.&lt;/p&gt;
&lt;p&gt;The collocation matrix is invertible if and only if the set of functions $\varphi$ are linearly independent.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;!--
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;If &lt;/p&gt;
$$p\left( u \right) = \sum\limits_{i=0}^{n} \alpha_i \varphi_i \left( u \right)$$
&lt;p&gt;
So that for every $j$, $p\left( u_j \right) = \sum\limits_{i=0}^{n} \alpha_i \varphi_i \left( u_j \right)$, thus the $\alpha_i$ lead to a linear system of the form
&lt;/p&gt;
$$\Phi \alpha = p$$
&lt;p&gt;
where $\Phi$ is the &lt;strong&gt;Vandermonde matrix&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



--&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Lagrange Polynomials&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;The &lt;strong&gt;Lagrange form of an interpolating polynomial&lt;/strong&gt; is given by
\begin{equation}
p \left( x\right) = \sum\limits_{i=0}^{n} p_i l_i\left(x\right)
\end{equation}&lt;/p&gt;
&lt;p&gt;where $l_{i} \in \mathbb{P}\_{n}$ such that $l_{i}\left( x_{j} \right) = \delta_{ij}$. The polynomials $l_i\left(x\right) \in \mathbb{P}\_n$ for $i=0, \ldots, n$, are called &lt;strong&gt;characteristic polynomials&lt;/strong&gt; and are given by
\begin{equation}
l_{i} \left( x \right) = \prod \limits_{\substack{j = 0,\newline{}j \ne i}}^{n} \dfrac{x - x_j}{x_i - x_j}. &lt;br&gt;
\end{equation}&lt;/p&gt;
&lt;p&gt;By construction, &lt;em&gt;the collocation matrix is the identity matrix&lt;/em&gt;. Thus, there is no need to invert the matrix to solve for the weights $\alpha$.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Newton Interpolation&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Newton interpolation interpolates a set of points $(x_i, y_i)$ as ${p \left( x\right) = \sum\limits_{i=0}^{n} \alpha_i n_i\left(x\right)}$ using a linear combination of Newton basis polynomials, which are defined as
&lt;/p&gt;
$$
n_0(x) = 1, \quad n_i(x) = \left(x - x_0 \right) \left(x - x_1 \right) \cdots \left(x - x_{i-1} \right).
$$
&lt;p&gt;
By construction, $\alpha_0=y_0$, and subsequent terms must be solved by evaluating the interpolating polynomial at increasing orders, leading to the formula
&lt;/p&gt;
$$
\alpha_{i+1} = \dfrac{ y_{i+1} - p_i \left( x_{i+1} \right) }{ n_i \left(  x_{i+1} \right) }.
$$
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Example open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Example:	&lt;em&gt;Lagrange Interpolation&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;An &lt;code&gt;.ipynb&lt;/code&gt; notebook with an example of interpolation using Lagrange polynomials can be accessed online 
.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Example open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Example:	&lt;em&gt;Runge&amp;#39;s Phenomenon&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;An &lt;code&gt;.ipynb&lt;/code&gt; notebook with an example of Runge&amp;rsquo;s phenomenon can be accessed online 
.&lt;/p&gt;
&lt;p&gt;It can be downloaded from 
 as a python file or downloaded as a notebook from 
.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;&lt;strong&gt;Aitken&amp;rsquo;s&lt;/strong&gt; algorithm is an iterative process for evaluating Lagrange interpolation polynomials at an arbitrary point, $u^*$, without explicitly constructing them. If the interpolating polynomial is given by $p$, and is derived from $n$ data points $(u_i, y_i)$ for $i=0,\ldots,n$&lt;/p&gt;
$$
p\left( u \right) = \sum\limits_{i=0}^{n} p_{i}^{n} l_i^{n}\left( u \right)
$$
&lt;!-- Let $p_{i,j}$ be polynomials of degree $j − i$ which pass through the points $\left(u_k, y_k\right)$ for $k = i, i + 1, \ldots, j$. --&gt;
&lt;p&gt;The interpolation is achieved by constructing a series of polynomials, evaluated at the ${u=u^{*}}$, where $p_{i}^{k}\left( u \right)$ is given by&lt;/p&gt;
$$
p_i^{k+1}\left(u\right) = p_i^k\left(u\right) \left( \dfrac{u - u_{n-k}}{u_i - u_{n-k}} \right) + p_{n-k}^k\left(u\right) \left( 1- \dfrac{u - u_{n-k}}{u_i - u_{n-k}} \right)
$$
&lt;p&gt;with initial values $p_i^0 = y_i^{\vphantom{0}}$.&lt;/p&gt;
$$
\begin{equation}
\begin{array}{lllll}
p\left( u_0 \right) = p_{0}^0 &amp;                       &amp;                        &amp;  \\\
                              &amp; p_0^1 &amp;                        &amp;  \\\
p\left( u_1 \right) = p_{1}^0 &amp;                       &amp; p_0^2  &amp;  \\\
                              &amp; p_1^1 &amp;                        &amp; p_0^3 \\\
p\left( u_2 \right) = p_{2}^0 &amp;                       &amp; p_1^2  &amp;  \\\
                              &amp; p_2^1 &amp;                        &amp;  \\\
p\left( u_3 \right) = p_{3}^0 &amp;                       &amp;                        &amp;
\end{array}
\end{equation}
$$
&lt;p&gt;where the coefficients are evaluated from left to right.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;!-- &lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;polynomial&amp;rsquo;s convergence.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



--&gt;
&lt;h2 id=&#34;piecewise-polynomial-interpolation&#34;&gt;Piecewise Polynomial Interpolation&lt;/h2&gt;
&lt;h2 id=&#34;spline-interpolation&#34;&gt;Spline Interpolation&lt;/h2&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;A function $s\left(u\right)$ is called a &lt;strong&gt;spline&lt;/strong&gt; of degree $k$ on the domain ${[a, b]}$ if ${s \in C^{k-1}\left( [a, b] \right)}$ and there exists nodes ${a = u_0 \lt u_1 \lt \ldots \lt u_m = b}$ such that $s$ is a polynomial of degree $k$ for ${i = 0, \ldots m-1}$.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;B-Splines&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;A spline is said to be a &lt;strong&gt;b-spline&lt;/strong&gt; if it is of the form&lt;/p&gt;
$$
s\left(u\right) = \sum\limits_{i=0}^{m} \alpha_{i} \mathcal{N}\_{i}^{n} \left(u \right)
$$
&lt;p&gt;where $\mathcal{N}^n$ are the &lt;strong&gt;basis spline functions&lt;/strong&gt; of degree $n$ with minimal support. (That is they are positive in the domain and zero outside). The functions are defined recursively. Let $u_i$ be the set of nodes ${u_0, u_1, \ldots, u_m}$, then&lt;/p&gt;
$$
\mathcal{N}\_{i}^{0} \left(u \right) =
\left\\{
\begin{array}{ll}
1 &amp; \quad \mbox{for} \quad u_i \le u \le u_{i+1} \\\
0 &amp; \quad \mbox{else.}
\end{array}
\right.
$$
&lt;p&gt;and&lt;/p&gt;
$$
\mathcal{N}\_{i}^{n} \left(u \right) = \alpha_i^{n-1}\left(u \right)  \mathcal{N}\_{i}^{n-1} \left(u \right) + \left( 1 - \alpha_{i+1}^{n-1}\left(u \right)\right)  \mathcal{N}\_{i+1}^{n-1} \left(u \right)
$$
&lt;p&gt;where&lt;/p&gt;
$$
\alpha_{i}^{n-1}\left(u \right) = \dfrac{u - u_i}{u_{i+n} - u_i}
$$
&lt;p&gt;
is a local parameter.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;p&gt;Given data with nodes $u_i$ and values $p_i$, to interpolate with splines, of order $n$, requires solving&lt;/p&gt;
$$
\mbox{Find} \quad s = \sum\limits_{i=0}^{m} \alpha_i \mathcal{N}_{i}^{n} \left( u\right) \quad \mbox{such that} \quad s\left(u_i \right) = p_i \quad \mbox{for} \quad i=0, \ldots, m
$$
&lt;p&gt;which is matrix form is ${\Phi \alpha = p}$, where the collocation matrix, $\Phi \in \mathbb{R}^{\left(m+1\right) \times \left(m+1\right)}$ is given by
&lt;/p&gt;
$$
\Phi = \left(
  \begin{array}{ccc}
  \mathcal{N}\_{0}^{n} \left(u_0\right) &amp; \cdots &amp; \mathcal{N}\_{m}^{n} \left(u_0\right) \\\
  \vdots &amp; &amp; \vdots \\\
  \mathcal{N}\_{0}^{n} \left(u_m\right) &amp; \cdots &amp; \mathcal{N}\_{m}^{n} \left(u_m\right)
  \end{array}
  \right).
$$
&lt;h2 id=&#34;least-squares-approximation&#34;&gt;Least-Squares Approximation&lt;/h2&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Least-Squares Approximation&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Given a set of points $y=\left( y_0, y_1, \ldots y_n \right)$ at nodes $x_0$, seek a continuous function of $x$, with a given form characterized by $m$ parameters $\beta=\left( \beta_0, \beta_1, \ldots, \beta_m \right)$, i.e. $f\left( x, \beta \right)$, which approximates the points while minimizing the error, defined by the sum of the squares
&lt;/p&gt;
$$
E = \sum\limits_{i=0}^{n} \left( y - f\left(x_i, \beta \right) \right)^2.
$$
&lt;p&gt;
The minimum is found when
&lt;/p&gt;
$$
\dfrac{\partial E}{\partial \beta_j} = 0 \quad \mbox{for all } \quad j=1, \ldots m
$$
&lt;p&gt;
i.e.
&lt;/p&gt;
$$
-2 \sum\limits_{i=0}^{n} \left(y_i - f\left(x_i, \beta_j \right) \right) \dfrac{\partial f\left( x_i, \beta \right)}{\partial \beta_j} = 0 \quad \mbox{for all } \quad j=1, \ldots m.
$$
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Linear Least-Squares Approximation&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;If the function $y(x)$ is a function of the form
&lt;/p&gt;
$$
y = \sum\limits_{j=1}^{m} \beta_j \varphi_j \left( x \right)
$$
&lt;p&gt;
where $\varphi_j$ are linearly independent, i.e. there is no non-zero constants $c_1$ and $c_2$ such that ${c_1 \varphi_i + c_2 \varphi_j =0}$ for all $x$. Then the least squares problem can be expressed as
&lt;/p&gt;
$$
E\left( \beta \right) = \sum\limits_{i=0}^n \left( y_i - \sum\limits_{j=0}^m \beta_j \varphi_j\left( x_i \right) \right)^2
$$
&lt;p&gt;
This has a minimum when
&lt;/p&gt;
$$
\dfrac{\partial E}{\partial \beta_j} = \sum\limits_{j=1}^m \left( \sum\limits_{i=1}^n \varphi_j\left( x_i \right) \varphi_k \left( x_i \right) \right) = 0.
$$
&lt;p&gt;
Thus, the weights $\beta$ can be determined by solving the &lt;strong&gt;normal equations&lt;/strong&gt;,
&lt;/p&gt;
$$
\Phi^T \Phi \beta = \Phi^T y,
$$
&lt;p&gt;
i.e. $\beta = \left( \Phi \Phi^T \right)^{-1} \Phi y$, where $\Phi$ is the collocation matrix.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



</description>
    </item>
    
    <item>
      <title>Integration</title>
      <link>https://djps.github.io/courses/numericalmethods24/part2/integration/</link>
      <pubDate>Fri, 17 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://djps.github.io/courses/numericalmethods24/part2/integration/</guid>
      <description>&lt;style&gt;
mjx-container {
  display: inline-block;
}
mjx-assistive-mml {
  right: 0px;
  bottom: 0px;
}
&lt;/style&gt;
&lt;p style=&#34;font-size: 14px; letter-spacing: 0.03em; color: rgb(0,0,0,0.54);&#34;&gt; &lt;span style=&#34;font-weight: 700;&#34;&gt; David Sinden &lt;/span&gt; &amp;middot;
&lt;i class=&#34;far fa-calendar&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; March 11, 2024 &amp;middot;
&lt;i class=&#34;far fa-clock&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; 45 minute read &lt;/p&gt;
&lt;h2 id=&#34;numerical-differentiation&#34;&gt;Numerical Differentiation&lt;/h2&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Finite-Difference Quotients&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Consider the approximations to the first-order derivative:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Forward Difference Quotient:&lt;/strong&gt;
$$
\begin{equation*}
D_{j}^{+} u = \dfrac{u_{j+1} - u_j}{h}
\end{equation*}
$$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Backwards Difference Quotient:&lt;/strong&gt;
$$
\begin{equation*}
D_{j}^{-} u = \dfrac{u_{j} - u_{j-1}}{h}
\end{equation*}
$$&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Central Difference Quotient:&lt;/strong&gt;
$$
\begin{equation*}
D_{j}^{0} u = \dfrac{u_{j+1} - u_{j-1}}{2h}
\end{equation*}
$$
The forward and backwards difference schemes are first order approximations to the derivative. The central difference scheme is a second order accurate approximation.&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Higher Order Derivatives&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Using the Taylor series of $f(x+h)$ and $f(x-h)$, the second-order derivative can be shown to be
&lt;/p&gt;
$$
f^{\prime\prime} \left( x \right) = \dfrac{ f(x - h) - 2 f (x) + f(x+h)}{h^2} + \mathcal{O} \left( h^2 \right) .
$$&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Richardson Extrapolation&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;This is a method for deriving higher order approximations for derivatives from lower order approximations. Consider a first-order approximation to the derivative, $\varphi\left(h\right)$, such as backwards or forwards differencing, then&lt;/p&gt;
$$
f^{\prime}\left( x \right) = \varphi\left(h\right) + a_2 h^2 + a_3 h^3 + \ldots
$$
&lt;p&gt;Now evaluate the derivative at ${h=h/2}$, so that&lt;/p&gt;
$$
f^{\prime}\left( x \right) = \varphi \left( h \right) + a_2 \left( \dfrac{h}{2} \right)^2 + a_3 \left( \dfrac{h}{2} \right)^3 + \ldots
$$
&lt;p&gt;Combining the two terms so that the low order term cancel, i.e. via ${f^{\prime}\left( x \right) - 4 f^{\prime}\left( x \right)}$, then a better approximation can be found as&lt;/p&gt;
$$
f^{\prime}\left( x \right) = \varphi \left( h \right) - 4 \varphi \left( \dfrac{h}{2} \right) + \mathcal{O}\left(h^3\right).
$$
&lt;p&gt;The process can also be applied to second order accurate schemes, such as central differencing, to produce more accurate approximations. The method can also be applied to higher order derivatives.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;h2 id=&#34;numerical-integration&#34;&gt;Numerical Integration&lt;/h2&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Riemann Sum&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Create a partition, $p$, of the domain of integration: define $n+1$ nodes ${a = x_0 &lt; x_1 &lt; \ldots &lt; x_n =b}$, so that there are $n$ sub-intervals $\left[x_i, x_{i+1} \right]$.
Then approximate the area under the curve by summing the areas in each subinterval defined as&lt;/p&gt;
$$
\int\limits_{a}^{b}f\left( x\right) \\, \mathrm{d}x \approx \sum\limits_{i=0}^{n-1} \left( x_{i+1} -x_i \right) f\left( x^{\ast} \right) \quad \mbox{where} \quad x^{\ast} \in \left[x_i, x_{i+1} \right].
$$
&lt;p&gt;If $f$ is continuous, the value of $x_{i}^{\ast}$ may be chosen arbitrarily in the interval $\left\[ x_i, x_{i+1} \right\]$. Then the &lt;strong&gt;lower&lt;/strong&gt; and &lt;strong&gt;upper Riemann sums&lt;/strong&gt; are given by&lt;/p&gt;
$$
\begin{align*}
L\left(f, p\right) = &amp; \sum\limits_{i=0}^{n-1} \left( x_{i+1} -x_i \right) m_i \quad \mbox{where} \quad  m_i = \min_{x\in\left[ x_i, x_{i+1} \right]} f\left(x \right), \\\
U\left(f, p\right) = &amp; \sum\limits_{i=0}^{n-1} \left( x_{i+1} -x_i \right) M_i \quad \mbox{where} \quad  M_i = \max_{x\in\left[ x_i, x_{i+1} \right]} f\left(x \right)
\end{align*}
$$
&lt;p&gt;
so that
&lt;/p&gt;
$$
L\left(f, p\right) \le \int_{a}^{b} f\left(x \right) \\, \mathrm{d}x \le U\left(f, p\right).
$$
&lt;p&gt;Additionally, the &lt;strong&gt;left&lt;/strong&gt; and &lt;strong&gt;right Riemann sums&lt;/strong&gt; are given , respectively, by
&lt;/p&gt;
$$
\begin{align*}
&amp; \sum\limits_{i=0}^{n-1} \left( x_{i+1} -x_i \right) f\left(x_{i-1} \right), \\\
&amp; \sum\limits_{i=0}^{n-1} \left( x_{i+1} -x_i \right) f\left(x_{i} \right).
\end{align*}
$$
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Trapezoidal Rule&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;&lt;a id=&#34;trap&#34;&gt;Rather than rectangles, use trapezoids to approximate the integral in a sub domain&lt;/a&gt;&lt;/p&gt;
$$
\int\limits_{a}^{b}f\left( x\right) \mathrm{d}x \approx \sum\limits_{i=0}^{n-1} \left( x_{i+1} - x_i \right) \dfrac{ f\left( x_{i} \right) + f\left( x_{i+1} \right)}{2}.
$$
&lt;p&gt;If the nodes of the partition are equally spaced, so that ${h=x_{i+1}-x_i}$, then the formula is given by
&lt;/p&gt;
$$
T\left(f,p\right) = \dfrac{h}{2} \left( f\left(x_0 \right) + f\left(x_n \right) \right) + h \sum\limits_{i=1}^{n-2}f\left( x_{i} \right).
$$
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;Error for Trapezoidal Rule&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Let ${f \in C^2\left( \left[a,b \right] \right)}$ and $p$ be equidistant partition of $\left[a,b \right]$, with ${h = x_{i+1} - x_i}$.&lt;/p&gt;
&lt;p&gt;The error can be shown to have the form:
&lt;/p&gt;
$$
\left| \int \limits_{a}^b f\left(x\right) \\, \mathrm{d}x - T\left(f,p\right) \right| = a_2 h^2 + a_4 h^4 + \ldots
$$
&lt;p&gt;that is, the error terms are even powers of the discretization.  More precisely, the error for the trapezium rule can be written as&lt;/p&gt;
$$
\left| \int_{a}^b f\left(x\right) \\, \mathrm{d}x - T\left(f,p\right) \right| = \dfrac{1}{12} \left| \left(b - a\right) h^2 f^{\prime\prime}\left( \xi \right) \right|
$$
&lt;p&gt;for some ${\xi \in \left(a, b\right)}$.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Simpson&amp;#39;s Rule&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;The integral is approximated as
&lt;/p&gt;
$$
\int_a^b f\left( x\right) \\, \mathrm{d}x \approx \dfrac{b-a}{6} \left( f\left(a\right) + 4 f\left(\dfrac{a+b}{2}\right) +f\left(b\right) \right).
$$
&lt;p&gt;
It can be applied in a composite manner, i.e. on many subdomains. It has an asymptotic error of $\mathcal{O}\left(h^4\right)$.&lt;/p&gt;
&lt;p&gt;Let ${h=\dfrac{b-a}{2}}$, then Simpson&amp;rsquo;s Rule is written as
&lt;/p&gt;
$$
\int_a^b f\left( x\right) \\, \mathrm{d}x \approx \dfrac{h}{3} \left( f\left(a\right) + 4 f\left( a + h \right) +f\left(b\right) \right)
$$
&lt;p&gt;
and is referred to as &lt;strong&gt;Simpson&amp;rsquo;s 1/3 Rule&lt;/strong&gt;. It uses quadratic interpolation of the function through the end and midpoints.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Algorithm open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Algorithm:	&lt;em&gt;Romberg Algorithm&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Romberg&amp;rsquo;s method uses the Trapezoidal Rule and then Richardson Extrapolation to estimate integrals.
First consider a sequence of partitions, $p_i$, for ${i=0, \ldots, n}$, of equal spacing given by ${h_i = \dfrac{b-a}{2^i}}$ which yield a sequence of integrals
${R_i^0 = T_i \left( f, p_i \right)}$. Refinements of the integrals can then be produced by Richardson Extrapolation:&lt;/p&gt;
$$
\begin{array}{cc}
R_0^0 &amp;       \\\
      &amp; R_1^1 \\\
R_1^0 &amp;       \\\
      &amp; R_2^1 \\\
R_2^0 &amp;       \\\
\vdots &amp; \\\
R_n^0  &amp;
\end{array}
$$
&lt;p&gt;To evaluate the next set of values, consider the two integrals&lt;/p&gt;
$$
\begin{align*}
\int_{a}^{b} f\left( x \right) \\, \mathrm{d} x &amp; = R_{i-1}^0 + a_2 h^2 + a_4 h^4 + \ldots \\\
\int_{a}^{b} f\left( x \right) \\, \mathrm{d} x &amp; = R_{i}^0 + a_2 \left( \dfrac{h}{2} \right)^2 + a_4 \left( \dfrac{h}{2} \right)^4 + \ldots  
\end{align*}
$$
&lt;p&gt;Note that there no odd terms in the error. Then, define the next approximation as
&lt;/p&gt;
$$
R_i^1 = \dfrac{1}{3} \left( 4 R_i^0 - R_{i-1}^0 \right).
$$
&lt;p&gt;
which has an error $\mathcal{O}\left(h^4\right)$. The extrapolated values are equivalent to integrals approximated by Simpson&amp;rsquo;s rule. The recurrence formula can be derived
&lt;/p&gt;
$$
R_i^m = \dfrac{1}{4^m - 1} \left( 4^m R_i^{m-1} - R_{i-1}^{m-1} \right).
$$
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Example open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Example:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;An &lt;code&gt;.ipynb&lt;/code&gt; notebook with an example of numerical integration using the Trapezium rule can be accessed online 
.&lt;/p&gt;
&lt;p&gt;It can be downloaded from 
 as a python file or downloaded as a notebook from 
.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;h3 id=&#34;gaussian-quadrature&#34;&gt;Gaussian Quadrature&lt;/h3&gt;
&lt;p&gt;Generalise the quadrature formula so that an integral is approximated as
\begin{equation}
I_{n}[f] = \sum \limits_{i=0}^{n} A_{i} f\left( x_{i} \right).
\end{equation}
The above equation is a weighted sum of the values of $f$ at the points $x_{i}$, for $i=0, \ldots, n$. These points are said to be the &lt;em&gt;nodes&lt;/em&gt; of the quadrature formula, while the  $A_{i} \in \mathbb{R}$ are its &lt;em&gt;coefficients&lt;/em&gt; or &lt;em&gt;weights&lt;/em&gt;. Both weights and nodes depend in general on $n$.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Can the weights be chosen such that the error in an integral is minimized?&lt;/li&gt;
&lt;li&gt;Furthermore, can the nodes be chosen such that the integral can be further improved?&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Orthogonal functions&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Two real-valued functions $f(x)$ and $g(x)$ are said to be &lt;strong&gt;orthogonal&lt;/strong&gt; if&lt;/p&gt;
$$
\langle f, g \rangle = \int_a^b f(x) g(x) \mathrm{d} x = 0.
$$
&lt;p&gt;where $\langle f, g \rangle$ satisfies the conditions to be an inner product.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;Gaussian Quadrature&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Let $q\left(x\right)$ be a non-trivial polynomial of degree ${n+1}$ such that&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;it has $n+1$ distinct roots, denoted as $x_i$, in $\left[ a, b \right]$,&lt;/li&gt;
&lt;li&gt;the polynomial $q(x)$ satisfies
$$
  \int_{a}^{b} x^k q\left(x\right) \\, \mathrm{d}x = 0 \quad \mbox{for} \quad k=0,\ldots, n.
  $$
i.e. $q(x)$ is orthogonal to $x^k$.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Then, denote the integral as
&lt;/p&gt;
$$
I_n\left[ f\right] = \int_{a}^{b} f\left(x\right) \\, \mathrm{d}x = \sum\limits_{i=0}^n A_i  f\left( x_i \right)
$$
&lt;p&gt;
with nodes given by the roots of the orthogonal polynomial $q$, and weights given by $A_i = \int_{a}^{b} l_i \left(x\right) \\, \mathrm{d}x$, using 
 for all polynomials $f\left(x\right)$ of degree less than or equal to ${2n+1}$.&lt;/p&gt;
&lt;p&gt;Then, the integral $I_n\left[ f\right]$ integrates all polynomials of degree ${2n+1}$ &lt;em&gt;exactly&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;It is said that the degree of exactness of $I\left[ f\right]$ is ${2n+1}$.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Gauss-Legendre Quadrature&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;The Legendre polynomials are a set of orthogonal polynomials where
&lt;/p&gt;
$$
\int_{-1}^1 P_m(x) P_n(x) \\, \mathrm{d} x = 0 \quad \mbox{for} \quad n \ne m.
$$
&lt;p&gt;
and $P_0 = 1$. Thus, $P_1 = x$, ${P_2 = \left(3x^2 -1\right) / 2}$. The Legendre polynomials obey a recursive formula:
&lt;/p&gt;
$$
P_n = \dfrac{2n-1}{n} x P_{n-1}(x) - \dfrac{n-1}{n} P_{n-2}(x) \quad \mbox{for} \quad n \ge 2.
$$
&lt;p&gt;
Gauss-Legendre quadrature uses the roots of the Legendre polynomials as the nodes for integration, and weights may also be found by equating the quadrature expressions with the exact integrals for orders of $f(x)$, i.e. ${f(x)=1, x, x^2, \ldots}$&lt;/p&gt;
&lt;p&gt;The domain of integration can be scaled from $(-1,1)$ to $(a, b)$ via the invertible transformation
&lt;/p&gt;
$$
x = \dfrac{b-a}{2} t + \dfrac{a+b}{2},
$$
&lt;p&gt;
so that
&lt;/p&gt;
$$
\int_a^b f(x) \\, \mathrm{d}x = \dfrac{b - a}{2} \int_{-1}^1 f\left( \dfrac{b-a}{2} t + \dfrac{a+b}{2}\right) \\, \mathrm{d}t.
$$
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



</description>
    </item>
    
    <item>
      <title>Finite Difference Methods for Differential Equations</title>
      <link>https://djps.github.io/courses/numericalmethods24/part3/odes/</link>
      <pubDate>Tue, 14 May 2024 00:00:00 +0000</pubDate>
      <guid>https://djps.github.io/courses/numericalmethods24/part3/odes/</guid>
      <description>&lt;style&gt;
mjx-container {
  display: inline-block;
}
mjx-assistive-mml {
  right: 0px;
  bottom: 0px;
}
&lt;/style&gt;
&lt;!--
&lt;p style=&#34;font-size: 14px; letter-spacing: 0.03em; color: rgb(0,0,0,0.54);&#34;&gt; &lt;span style=&#34;font-weight: 700;&#34;&gt; David Sinden &lt;/span&gt; &amp;middot;
&lt;i class=&#34;far fa-calendar&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; May 15, 2024 &amp;middot;
&lt;i class=&#34;far fa-clock&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; 45 minute read &lt;/p&gt;


## Finite Difference Methods for Differential Equations
--&gt;
&lt;p&gt;Solutions are functions.&lt;/p&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Ordinary Differential Equations&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;An &lt;strong&gt;ordinary differential equation&lt;/strong&gt; (ODE) is an equation that involves one of more derivatives of a function of a single variable.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;!-- For example, with only the first derivative $y^{\prime} \left(t\right) = f\left( y\left(t\right), t)$  --&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Initial Value Problems&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;An &lt;strong&gt;initial value problem&lt;/strong&gt; (IVP) is given by an ordinary differential equation of the form ${y^{\prime} \left(t\right) = f\left( y\left(t\right), t\right)}$ and initial value ${y\left(a\right)=y_a}$ for the unknown function $y\left(t\right)$.&lt;/p&gt;
&lt;p&gt;Often ${a=0}$, so the initial condition reads ${y(0)=y_0}$.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;One step methods&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;A numerical method for approximating the solution to a differential equation is called a &lt;strong&gt;one step method&lt;/strong&gt; if the computed solution at time step $t_{n+1}$, denoted by $u_{n+1}$, only depends on the previous one, $t_i$, where $t_{n+1} = t_n + h$, for some small increment ${h=\Delta t}$.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;h3 id=&#34;forward-euler-method&#34;&gt;Forward Euler Method&lt;/h3&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;&lt;strong&gt;Forward Euler&lt;/strong&gt; approximates the derivative in an initial value problem using the forward difference approximation of first-order derivatives
&lt;/p&gt;
$$
u_{n+1} = u_n + h f_n
$$
&lt;p&gt;
where $u_n = u \left(t_n \right)$ and ${f_{n} = f\left( u_{n}, t_{n} \right)}$. The error is $\mathcal{O}\left( h^2 \right)$.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;h3 id=&#34;backward-euler-method&#34;&gt;Backward Euler Method&lt;/h3&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;&lt;strong&gt;Backward Euler&lt;/strong&gt; uses the backward finite difference approximation of the first-order derivative
&lt;/p&gt;
$$
u_{n+1} = u_n + h f_{n+1}
$$
&lt;p&gt;
where ${f_{n+1} = f\left( u_{n+1}, t_{n+1} \right) = f\left( u\left(t_{n+1} \right), t_{n+1} \right) }$. The error is $\mathcal{O}\left( h^2 \right)$.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;h3 id=&#34;crank-nicolson-method&#34;&gt;Crank-Nicolson Method&lt;/h3&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;The &lt;strong&gt;Crank-Nicolson method&lt;/strong&gt; is given by
&lt;/p&gt;
$$
u_{n+1} = u_n + \dfrac{h}{2}\left( f_n + f_{n+1} \right).
$$&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;h3 id=&#34;heuns-method&#34;&gt;Heun&amp;rsquo;s Method&lt;/h3&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;&lt;strong&gt;Heun&amp;rsquo;s method&lt;/strong&gt; is given by
&lt;/p&gt;
$$
u_{n+1} = u_n + \dfrac{h}{2}\left( f_n + f\left( u_n + h f_n, t_{n+1} \right) \right).
$$&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;A numerical method is said to be &lt;strong&gt;explicit&lt;/strong&gt; if an approximation $u_{k+1}$ can be calculated directly from already computed values $u_i$ for ${i &lt; k}$. Otherwise, the method is said to be &lt;strong&gt;implicit&lt;/strong&gt;.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;p&gt;Often, implicit methods require, at each step $k+1$, the solution of a nonlinear equation for computing $u_{k+1}$.&lt;/p&gt;
&lt;p&gt;Both the Forward Euler and Heun&amp;rsquo;s method are explicit. The Backward Euler and Crank-Nicolson methods are implicit.&lt;/p&gt;
&lt;p&gt;Huen&amp;rsquo;s method can be interpreted as the Crank-Nicolson method with the approximation ${u_{n+1} \approx u_n + h f_n}$ replacing the explicit $f_{n+1}$ term, which depends on $u_{n+1}$.&lt;/p&gt;
&lt;p&gt;Alternatively, the solution to the differential equation can be written as &lt;a href=&#34;https://djps.github.io/courses/numericalmethods24/part2/integration/#numerical-integration&#34;&gt;quadrature&lt;/a&gt;:
&lt;/p&gt;
$$
y\left( t + h \right) = y\left( t \right) + \int_{t}^{t+h} f\left( y\left(\tau\right), \tau \right) \, \mathrm{d}\tau.
$$
&lt;p&gt;Thus, the Forward Euler method is the left Riemann sum, Backward Euler is the right Riemann sum and the Crank-Nicolson is the trapezoidal rule.&lt;/p&gt;
&lt;h2 id=&#34;analysis-of-one-step-methods&#34;&gt;Analysis of One-Step Methods&lt;/h2&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;A function $f$ is &lt;strong&gt;Hölder continuous&lt;/strong&gt; if there exists real constants ${C \ge 0}$ and ${\alpha \lt 0}$ such that
&lt;/p&gt;
$$
\left| f\left(x\right) - f\left(y\right) \right| \le  C \Vert x - y\Vert^\alpha
$$
&lt;p&gt;
for all $x$ and $y$. If ${\alpha=1}$ the function is said to be &lt;strong&gt;Lipshitz continuous&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Consistency Error&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Any explicit one-step method has the form
&lt;/p&gt;
$$
u_{n+1} = u_n + h \Phi\left( t_n, u_n, f_n, h \right)
$$
&lt;p&gt;
with $\Phi$ the increment function. For the exact solution to the differential equation, $y\left(t_n \right) = y_n$, the solution is&lt;/p&gt;
$$
y_{n+1} = y_n + h \Phi\left( t_n, y(t_n), f_n, h \right) + \varepsilon_n  
$$
&lt;p&gt;which can be written as&lt;/p&gt;
$$
\tau_n = \dfrac{y_{n+1} - y_n}{h} - \Phi\left( t_n, y(t_n), f_n, h \right)
$$
&lt;p&gt;where $\varepsilon_n = h \tau_n$ for a ${\tau_n = \tau_n\left(h\right)}$ defined as the &lt;strong&gt;local truncation error&lt;/strong&gt; at step $n$.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;consistency error&lt;/strong&gt; is given by ${\tau = \max_n | \tau_n | }$.&lt;/p&gt;
&lt;p&gt;A method is said to be &lt;strong&gt;consistent&lt;/strong&gt; if $\lim\limits_{h \to 0} \Phi = f$. This means the increment function is a good approximation to the differential equation as the step size tends to zero.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Convergence&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;The &lt;strong&gt;global truncation error&lt;/strong&gt; is the difference between the exact solution, $y_n = y(t_n)$ and the approximate solution, $u_n$, at the time $t_n$,
&lt;/p&gt;
$$
\tau_{g,n} = \left| y_n - u_n \right|
$$
&lt;p&gt;
which is given by
&lt;/p&gt;
$$
\tau_{g,n} = \left| y_n - \left( u_0 + h\Phi\left(t_0, u_0, f_0, h\right) +h\Phi\left(t_1, u_1, f_1, h\right) + \ldots + h\Phi\left(t_n, u_n, f_n, h\right) \right) \right|.
$$
&lt;p&gt;
If $\lim\limits_{h\rightarrow 0} u_{n+1} = y\left(t_{n+1} \right)$ the method is said to be &lt;strong&gt;locally convergent&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The scheme is &lt;strong&gt;convergent&lt;/strong&gt; if the global truncation error goes to zero as the step size goes to zero, that is ${\lim\limits_{h \to 0} \max\limits_{n} | \tau_{g,n}  | = 0}$.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Order&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;A one-step method is of order $p \in \mathbb{N}$, if for all ${t \in \left[ 0, T \right]}$, the solution satisfies the condition that ${\tau\left(h\right) = \mathcal{O}\left( h^p \right) }$ as ${h \rightarrow 0}$.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Zero Stable Methods&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;A method of the form
&lt;/p&gt;
$$
u_{n+1} = u_n + h \Phi\left( t_n, u_n, f_n, h \right)
$$
&lt;p&gt;
with $\Phi$ the increment function, is called &lt;strong&gt;zero-stable&lt;/strong&gt; if there exists both a maximal step size, $h_{\mathrm{max}}$ and a constant, $C$, such that for all ${h \in \left[0, h_{\mathrm{max}} \right]}$ and for some ${\varepsilon \gt 0}$, then the following holds:&lt;/p&gt;
&lt;p&gt;If, for all time-steps ${0 \le n \le N}$, there exists a ${\delta_n \le \varepsilon}$ and if a method is given by
&lt;/p&gt;
$$
z_{n+1} = z_n + h \Phi\left( t_n, z_n, f_n\left(z_n, t_n\right), h \right) + \delta_{n+1}
$$
&lt;p&gt;with $z_0 = {y_0 +\delta_0}$, then&lt;/p&gt;
$$
\left\| z_n - u_n \right\| \le C \varepsilon \quad \text{for} \quad 0 \le n \le N.
$$
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;p&gt;If a method is zero-stable, then this means that small perturbations in the computations lead to small perturbations in the approximations.&lt;/p&gt;
&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;If the increment function $\Phi$ of a one step numerical scheme is Lipshitz continuous for $u_n$ for any $h$ and $t_n$, then the one step method is zero-stable.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;If the increment function $\Phi$ is&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Lipshitz continuous for $y_n$ for any $h$ and $t_{n+1}$,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the method is &lt;a href=&#34;https://djps.github.io/courses/numericalmethods24/part-1/linear-equations/#fundamental-theorem-of-numerical-analysis&#34;&gt;consistent&lt;/a&gt;, i.e. $\lim\limits_{h \rightarrow 0} \tau \left(h \right) = 0$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if $\left| y_0 - u_0 \right| \rightarrow 0$ as $h \rightarrow 0$,&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;then the global error has
&lt;/p&gt;
$$
\lim \limits_{h \rightarrow 0} \left| y_n - u_n \right| = 0.
$$
&lt;p&gt;
Also, if the method is of order $p$ and if ${\left| y_0 - u_0 \right| = \mathcal{O}\left(h^p\right)}$ as ${h\rightarrow 0}$, then the convergence is of order $p$.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;Absolute Stability&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;A numerical scheme for approximating the solution to the linear differential equation ${y^{\prime}\left(t\right) = \lambda y\left(t\right)}$ with ${\lambda \in \mathbb{C}}$ and initial condition ${y_0}$ is said to be &lt;strong&gt;absolutely stable&lt;/strong&gt; if ${\left|u_n\right| \rightarrow 0}$ as ${n \rightarrow \infty}$, when ${\operatorname{Re}\left(\lambda\right) \lt 0}$ for a fixed value of $h$.&lt;/p&gt;
&lt;p&gt;The region of absolute stability of a numerical method for ${y^{\prime}\left(t\right) = \lambda y\left(t\right)}$ is the set&lt;/p&gt;
$$
\lbrace h \lambda \in \mathbb{C} \quad \text{such that} \quad  | u_n | \rightarrow 0 \quad \text{as} \quad t_n \rightarrow \infty \rbrace.
$$
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;p&gt;Zero stability considers when ${h \rightarrow 0}$, whereas absolute stability concerns behaviour as ${t_n \rightarrow \infty}$.&lt;/p&gt;
&lt;h2 id=&#34;lax-equivalence&#34;&gt;Lax Equivalence&lt;/h2&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;A problem is said to be &lt;strong&gt;well-posed&lt;/strong&gt; if&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a unique solution exists for any initial conditions and&lt;/li&gt;
&lt;li&gt;the solution&amp;rsquo;s behaviour changes continuously with the initial conditions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A problem which does not have these properties is said to be &lt;strong&gt;ill-posed&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;div class=&#34;details admonition Theorem open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Theorem:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;The Lax Equivalence theorem or Lax–Richtmyer theorem is the equivalent form of the &lt;a href=&#34;https://djps.github.io/courses/numericalmethods24/part-1/linear-equations/#fundamental-theorem-of-numerical-analysis&#34;&gt;fundamental theorem of numerical analysis&lt;/a&gt; for differential equations, which states that a &lt;em&gt;consistent&lt;/em&gt; finite difference method for a well-posed linear initial value problem, the method is &lt;em&gt;convergent&lt;/em&gt; if and only if it is &lt;em&gt;stable&lt;/em&gt;.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;!--
https://www.danlj.org/eaj/math/summaries/ftna/ftna.pdf
https://people.maths.ox.ac.uk/trefethen/4all.pdf
For a _partial_ differential equation, consistency means that a solution to the initial value problem approximately satisfies the discretized equation as the mesh size goes to zero, thus the error, i.e. the difference between the analytical solution and the computed solution tends to zero as the
For an initial value problem, consistency means that the error committed by the numerical algorithm over a single time step is small.
For an initial value problem, the fundamental theorem simply says that if the error committed on each time step is small enough, and if the rate of error growth is bounded, than the error in the solution will remain small.
--&gt;
&lt;h2 id=&#34;runge-kutta-and-multi-step-schemes&#34;&gt;Runge-Kutta And Multi-Step Schemes&lt;/h2&gt;
&lt;p&gt;If an ordinary differential equation is given by ${\dot{y}= f\left( y, t \right)}$, then a Runge-Kutta scheme takes the form&lt;/p&gt;
$$
u_{n+1} = u_n + h F\left( t_n, u_n, h; f \right)
$$
&lt;p&gt;where $F$ is an increment function given by&lt;/p&gt;
$$
F\left( t_n, u_n, h; f \right) = \sum\limits_{i=1}^s b_i k_i
$$
&lt;p&gt;with $k_i$ defined as&lt;/p&gt;
$$
k_i = f\left( u_n + h\sum_{j=1}^s a_{i, j} k_j, t_n + c_i h \right) \quad i=1, \ldots, s
$$
&lt;p&gt;where $s$ is referred to as the number of stages of the method.&lt;/p&gt;
&lt;p&gt;Thus, an $s$-stage scheme is characterised by coefficients $b_i$, $c_i$ and $a_{i,j}$ for ${i, j = 1,\ldots s}$&lt;/p&gt;
&lt;p&gt;If the matrix defined by the elements $a_{i,j}$ is lower triangular, i.e. ${a_{i,j}=0}$ for all ${i \le j}$, then each $k_i$ can be computed explicitly in terms of the previous coefficients ${k_1, \ldots, k_{i-1}}$. Such schemes are &lt;strong&gt;explicit&lt;/strong&gt;, otherwise they are said to be &lt;strong&gt;implicit&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The components of a Runge-Kutta scheme are expressed in a Butcher array
&lt;/p&gt;
$$
\begin{array}{c|cccc}
c_1    &amp; a_{1,1} &amp; \ldots &amp; a_{1,s} \\
\vdots &amp; \vdots  &amp; \ddots &amp; \vdots  \\
c_s    &amp; a_{s,1} &amp; \ldots &amp; a_{s,s} \\
\hline
       &amp; b_1     &amp; \ldots &amp; b_s
\end{array}
$$
&lt;p&gt;The &lt;strong&gt;local truncation error&lt;/strong&gt;, which characterises the error induced at each step of the method, is defined as
&lt;/p&gt;
$$
h \tau_{n+1}\left(h\right) = y\left(t_{n+1} \right) - y\left(t_{n} \right) - h F\left( t_n, u_n, h; f \right).
$$
&lt;p&gt;It can be shown that ${\tau\left(h\right) = \max\left| \tau_{n+1}\left(h\right) \right| \rightarrow 0}$ as ${h \rightarrow 0}$ if and only if ${\sum_{i=1}^s b_i = 1}$.&lt;/p&gt;
&lt;p&gt;A Runge-Kutta method is of order ${p \ge 1}$ if ${\tau\left( h \right) = \mathcal{O}\left( h^p \right)}$ as ${h \rightarrow 0}$.&lt;/p&gt;
&lt;p&gt;The order of an $s$-stage &lt;em&gt;explicit&lt;/em&gt; Runge-Kutta method cannot be greater than $s$. Additionally, there does not exist a $s$-stage explicit Runge-Kutta method with order $s$ if ${s \ge 5}$.&lt;/p&gt;
&lt;p&gt;The order of an $s$-stage &lt;em&gt;implicit&lt;/em&gt; Runge-Kutta method cannot be greater than $2s$.&lt;/p&gt;
&lt;h3 id=&#34;runge-kutta-4&#34;&gt;Runge-Kutta 4&lt;/h3&gt;
&lt;p&gt;The most common form of the Runge-Kutta method is the fourth order Runge-Kutta method (RK4). It takes the form:&lt;/p&gt;
$$
u_{n+1} = u_n + \dfrac{h}{6} \left( k_1 + 2k_2 + 2 k_3 + k_4 \right)
$$
&lt;p&gt;
where
&lt;/p&gt;
$$
\begin{align*}
k_1 &amp; = f\left( u_n, t_n \right), \\\
k_2 &amp; = f\left( u_n + \dfrac{h}{2} k_1, t_n + \dfrac{h}{2} \right), \\\
k_3 &amp; = f\left( u_n + \dfrac{h}{2} k_2, t_n + \dfrac{h}{2} \right), \\\
k_4 &amp; = f\left( u_n + h k_3, t_n + h \right).
\end{align*}
$$
&lt;div class=&#34;details admonition Example open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; viewBox=&#34;0 0 370 391&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&lt;g clip-rule=&#34;evenodd&#34; fill-rule=&#34;evenodd&#34;&gt;&lt;path d=&#34;m207.5 22.4 114.4 66.6c13.5 7.9 21.9 22.4 21.9 38v136.4c0 17.3-9.3 33.3-24.5 41.8l-113.5 63.9a49.06 49.06 0 0 1 -48.5-.2l-104.5-60.1c-16.4-9.5-26.6-27-26.6-45.9v-129.5c0-19.1 9.9-36.8 26.1-46.8l102.8-63.5c16-9.9 36.2-10.1 52.4-.7z&#34; fill=&#34;#ff4088&#34; stroke=&#34;#c9177e&#34; stroke-width=&#34;27&#34; /&gt;&lt;path d=&#34;m105.6 298.2v-207.2h43.4v75.5h71.9v-75.5h43.5v207.2h-43.5v-90.6h-71.9v90.6z&#34; fill=&#34;#fff&#34; /&gt;&lt;/g&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Example:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;An &lt;code&gt;.ipynb&lt;/code&gt; notebook with an example of solvers for odes can be accessed online &lt;a href=&#34;https://djps.github.io/courses/numericalmethods24/notebooks/ode_solvers/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It can be downloaded from &lt;a href=&#34;https://djps.github.io/ipyth/ode_solvers.py&#34;&gt;here&lt;/a&gt; as a python file or downloaded as a notebook from &lt;a href=&#34;https://djps.github.io/ipyth/ode_solvers.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;h2 id=&#34;partial-differential-equations&#34;&gt;Partial Differential Equations&lt;/h2&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
    &lt;div class=&#34;details-summary admonition-title&#34;&gt;
        
        &lt;span class=&#34;pr-3 pt-1 text-primary-600 dark:text-primary-300&#34;&gt;
          &lt;svg height=&#34;24&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;m11.25 11.25l.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0a9 9 0 0 1 18 0m-9-3.75h.008v.008H12z&#34;/&gt;&lt;/svg&gt;
        &lt;/span&gt;
        Definition:	&lt;em&gt;&lt;/em&gt;
    &lt;/div&gt;
    &lt;div class=&#34;details-content&#34;&gt;
        &lt;div class=&#34;admonition-content&#34;&gt;A &lt;strong&gt;partial differential equation&lt;/strong&gt; is relation involving a unknown function of several free variables and partial derivatives with respect to these variables.&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;



&lt;p&gt;A partial differential equation is said to be linear if it only contains linear terms of the unknown and its derivatives. For example, a second-order linear partial differential equation for a function ${u=u(x,t)}$&lt;/p&gt;
$$
a_1(x,t) u_{xx} + a_2(x,t) u_{xt} + a_3 u(x,t)_{tt} + a_3(x,t) u_x + a_4(x,t) u_t + a_5(x,t) u = f(x,t).
$$
&lt;p&gt;where $u_{xx} = \dfrac{\partial^2 u}{\partial x^2}$, etc.&lt;/p&gt;
&lt;p&gt;For finite-difference schemes, &lt;em&gt;all&lt;/em&gt; partial derivatives must be approximated by &lt;a href=&#34;https://djps.github.io/courses/numericalmethods24/part-2/integration/#numerical-differentiation&#34;&gt;discretized differential operators&lt;/a&gt;.&lt;/p&gt;
&lt;!--
CFL.

Heat Equation
--&gt;
</description>
    </item>
    
  </channel>
</rss>
