<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>JTMS-MAT-13: Numerical Methods | David Sinden</title>
    <link>https://djps.github.io/courses/numericalmethods24/</link>
      <atom:link href="https://djps.github.io/courses/numericalmethods24/index.xml" rel="self" type="application/rss+xml" />
    <description>JTMS-MAT-13: Numerical Methods</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Tue, 14 Nov 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://djps.github.io/media/logo_hud7cfbe45e4df55bd5c7c181ea654d8f2_56982_300x300_fit_lanczos_3.png</url>
      <title>JTMS-MAT-13: Numerical Methods</title>
      <link>https://djps.github.io/courses/numericalmethods24/</link>
    </image>
    
    <item>
      <title>Taylor Series</title>
      <link>https://djps.github.io/courses/numericalmethods24/part-1/taylor/</link>
      <pubDate>Thu, 07 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://djps.github.io/courses/numericalmethods24/part-1/taylor/</guid>
      <description>&lt;!--
&lt;p style=&#34;font-size: 14px; letter-spacing: 0.03em; color: rgb(0,0,0,0.54); border-top: 1px solid #e8e8e8; margin-top: 30px; padding-top: 10px; border-bottom: 1px solid #e8e8e8; margin-bottom: 30px; padding-bottom: 10px;&#34;&gt; &lt;span style=&#34;font-weight: 700;&#34;&gt; David Sinden &lt;/span&gt; &amp;middot;
&lt;i class=&#34;far fa-calendar&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; March 11, 2022 &amp;middot;
&lt;i class=&#34;far fa-clock&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; 45 minute read &lt;/p&gt;
--&gt;
&lt;p style=&#34;font-size: 14px; letter-spacing: 0.03em; color: rgb(0,0,0,0.54);&#34;&gt; &lt;span style=&#34;font-weight: 700;&#34;&gt; David Sinden &lt;/span&gt; &amp;middot;
&lt;i class=&#34;far fa-calendar&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; December 07, 2023 &amp;middot;
&lt;i class=&#34;far fa-clock&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; 15 minute read &lt;/p&gt;
&lt;h2 id=&#34;taylor-series&#34;&gt;Taylor Series&lt;/h2&gt;
&lt;p&gt;The Taylor series, or Taylor expansion of a function, is defined as&lt;/p&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Taylor Series&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;For a function $f : \mathbb{R} \mapsto \mathbb{R}$ which is infinitely differentiable at a point $c$, the Taylor series of $f(c)$ is given by
\begin{equation}
\sum\limits_{k=0}^{\infty} \dfrac{ f^{(k)} \left( c \right) }{k!} \left( x - c \right)^{k}.
\end{equation}&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;p&gt;This is a power series, which is convergent for some radius.&lt;/p&gt;
&lt;div class=&#34;details admonition Theorem open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-list-ul fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Theorem:	&lt;em&gt;Taylor&amp;#39;s Theorem&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;For a function $f \in C^{n+1}\left([a, b]\right)$, i.e. $f$ is $(n+1)$-times continuously differentiable in the interval $[a, b]$, then for some $c$ in the interval, the function can be written as
\begin{equation}
f\left( x \right) = \sum\limits_{k=0}^{n} \dfrac{f^{(k)} \left(c\right) }{k!} \left( x- c \right)^{k} + \dfrac{f^{(n+1)} \left( \xi \right) }{\left( n + 1 \right)!} \left( x - c \right)^{n+1}
\end{equation}
for some value $\xi \in \left[ a, b \right]$ where
\begin{equation}
\lim\limits_{\xi \rightarrow c} \dfrac{ f^{(n+1)} \left( \xi \right) }{ \left( n + 1 \right)!} \left( x - c \right)^{n+1} = 0.
\end{equation}&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Example open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-cogs fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Example:	&lt;em&gt;&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;An &lt;code&gt;.ipynb&lt;/code&gt; notebook with an example of the Taylor series for $\sin\left(x\right)$ can be accessed online &lt;a href=&#34;https://djps.github.io/courses/numericalmethods24/notebooks/taylor_series/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It can be downloaded from &lt;a href=&#34;https://djps.github.io/ipyth/TaylorSeries.py&#34;&gt;here&lt;/a&gt; as a python file or downloaded as a notebook from &lt;a href=&#34;https://djps.github.io/ipyth/TaylorSeries.ipynb&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Number Representations</title>
      <link>https://djps.github.io/courses/numericalmethods24/part-1/number-representations/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://djps.github.io/courses/numericalmethods24/part-1/number-representations/</guid>
      <description>&lt;style&gt;
mjx-container {
  display: inline-block;
}
mjx-assistive-mml {
  right: 0px;
  bottom: 0px;
}
&lt;/style&gt;
&lt;!--
&lt;p style=&#34;font-size: 14px; letter-spacing: 0.03em; color: rgb(0,0,0,0.54); border-top: 1px solid #e8e8e8; margin-top: 30px; padding-top: 10px; border-bottom: 1px solid #e8e8e8; margin-bottom: 30px; padding-bottom: 10px;&#34;&gt; &lt;span style=&#34;font-weight: 700;&#34;&gt; David Sinden &lt;/span&gt; &amp;middot;
&lt;i class=&#34;far fa-calendar&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; March 11, 2022 &amp;middot;
&lt;i class=&#34;far fa-clock&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; 45 minute read &lt;/p&gt;
--&gt;
&lt;p style=&#34;font-size: 14px; letter-spacing: 0.03em; color: rgb(0,0,0,0.54);&#34;&gt; &lt;span style=&#34;font-weight: 700;&#34;&gt; David Sinden &lt;/span&gt; &amp;middot;
&lt;i class=&#34;far fa-calendar&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; January 05, 2024 &amp;middot;
&lt;i class=&#34;far fa-clock&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; 25 minute read &lt;/p&gt;
&lt;h2 id=&#34;errors&#34;&gt;Errors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Errors in data&lt;/li&gt;
&lt;li&gt;Round-off errors&lt;/li&gt;
&lt;li&gt;Truncation errors&lt;/li&gt;
&lt;/ul&gt;
&lt;!--  $\left| \dfrac{\tilde{a}-a}{a} \right|$  --&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Absolute and Relative Errors&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Let $\tilde{a}$ be an approximation to $a$, then the &lt;strong&gt;absolute error&lt;/strong&gt; is given by $\left| {\tilde{a}-a} \right|$.&lt;/p&gt;
&lt;p&gt;If ${a \ne 0}$, the &lt;strong&gt;relative error&lt;/strong&gt; is given by $\left| \dfrac{\tilde{a}-a}{a} \right|$ and the error bound is the magnitude of the admissible error.&lt;/p&gt;
&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Theorem open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-list-ul fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Theorem:	&lt;em&gt;&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;For both addition and subtraction the bounds for the absolute error are added.&lt;/p&gt;
&lt;p&gt;In division and multiplication the bounds for the relative errors are added.&lt;/p&gt;
&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;p&gt;Error propagation&lt;/p&gt;
&lt;p&gt;Numerical methods are a lot of computational schemes to solve mathematical problems when analytical solutions can&amp;rsquo;t be found.&lt;/p&gt;
&lt;p&gt;How does the representation of a number in computer memory affect calculations?&lt;/p&gt;
&lt;h2 id=&#34;number-representations&#34;&gt;Number Representations&lt;/h2&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Base Representation&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Let $b \in \mathbb{N} \backslash \lbrace 1 \rbrace$. Every number $x \in \mathbb{N}_0$
can be written as a unique expansion with respect to base $b$ as&lt;/p&gt;
&lt;p&gt;\begin{equation}
x = a_0 b^0 + a_1 b^1 + \ldots a_n b^n = \sum \limits_{i=0}^{n} a_i b^i
\end{equation}&lt;/p&gt;
&lt;p&gt;with $a_i &amp;lt; \mathbb{N}_0$ and $a_i &amp;lt; b$, i.e. ${a_i \in \lbrace 0, \ldots, b-1 \rbrace }$&lt;/p&gt;
&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Algorithm open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-laptop-code fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Algorithm:	&lt;em&gt;Euclid&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;Euclid&amp;rsquo;s algorithm can convert number $x$ in base 10, i.e.
$\left(x \right)_{10}$
into another base, $b$, i.e. $\left(y \right)_{b}$.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Input $\left(x \right)_{10}$&lt;/li&gt;
&lt;li&gt;Determine the smallest integer $n$ such that ${x &amp;lt; b^{n+1}}$&lt;/li&gt;
&lt;li&gt;Let $y=x$. Then for $i=n, \ldots, 0$
$$
\begin{array}{rcl}
a_i &amp;amp; = &amp;amp; y \mbox{ div } b^i \\
y &amp;amp; = &amp;amp; y \mbox{ mod } b^i
\end{array}
$$&lt;/li&gt;
&lt;li&gt;Output as $\left(x \right)_{10} = a_n a_{n-1} \cdots a_0$&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Algorithm open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-laptop-code fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Algorithm:	&lt;em&gt;Horner&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;Here&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Normalized Floating Point Representations&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;Normalized floating point representations with respect to some base $b$, store a number $x$ as
$$x= 0 \cdot a_1 \ldots a_k \times b^n$$
where the $a_i \in \lbrace 0, 1, \ldots b-1 \rbrace$ are called the &lt;strong&gt;digits&lt;/strong&gt;, $k$ is the &lt;strong&gt;precision&lt;/strong&gt; and $n$ is the &lt;strong&gt;exponent&lt;/strong&gt;. The set $a_1, \ldots, a_k$ is called the &lt;strong&gt;mantissa&lt;/strong&gt;. Impose that $a_1 \ne 0$, it makes the representation unique.&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Significant Bits&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;Here&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Theorem open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-list-ul fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Theorem:	&lt;em&gt;&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;Let $x$ and $y$ be two normalized floating point numbers with ${x &amp;gt; y &amp;gt; 0}$ and base ${b=2}$. If there exists integers $p$ and ${q \in \mathbb{N}_0}$ such that
$$2^{-p} \leq 1 - \dfrac{y}{x} \leq 2^{-q}$$
then, at most $p$ and at least $q$ significant bits (i.e. digits at base $2$) are lost during subtraction.&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Linear Equations</title>
      <link>https://djps.github.io/courses/numericalmethods24/part-1/linear-equations/</link>
      <pubDate>Mon, 20 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://djps.github.io/courses/numericalmethods24/part-1/linear-equations/</guid>
      <description>&lt;h2 id=&#34;linear-equations&#34;&gt;Linear Equations&lt;/h2&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Linear Systems of Equations&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;Here: linear, square.&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Banded Systems&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;Here&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Symmetric Matrices&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;A square matrix $A$ is &lt;strong&gt;symmetric&lt;/strong&gt; if ${A=A^T}$, that is, $a_{i,j}=a_{j,i}$ for all indices $i$ and $j$.&lt;/p&gt;
&lt;p&gt;A square matrix is said to be &lt;strong&gt;Hermitian&lt;/strong&gt; if the matrix is equal to its conjugate transpose, i.e. $a_{i,j}=\overline{a_{j,i}}$ for all indices $i$ and $j$. A Hermitian matrix is written as $A^H$.&lt;/p&gt;
&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Positive Definite Matrices&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;A matrix, $M$, is said to be &lt;strong&gt;positive definite&lt;/strong&gt; if it is symmetric (or Hermitian) and all its eigenvalues are real and positive.&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Nonsingular Matrices&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;A matrix is &lt;strong&gt;non-singular&lt;/strong&gt; or &lt;strong&gt;invertible&lt;/strong&gt; if there exists a matrix $A^{-1}$ such that ${A^{-1}A = A A^{-1} = I}$, where $I$ is the identity matrix.&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Note open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-pencil-alt fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Note:	&lt;em&gt;Properties of Nonsingular Matrices&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;For a nonsingular matrix, the following all hold:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nonsingular matrix has full rank&lt;/li&gt;
&lt;li&gt;A square matrix is nonsingular if and only if the determinant of the matrix is non-zero.&lt;/li&gt;
&lt;li&gt;If a matrix is singular, both versions of Gaussian elimination will fail due to division by zero, yielding a floating exception error.&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;If $\tilde{x}$ is an approximate solution to the linear problem ${Ax=b}$, then the &lt;strong&gt;residual&lt;/strong&gt; is defined as ${r = A \tilde{x}-b}$.&lt;/p&gt;
&lt;p&gt;If $\left| r \right|$ is large due to rounding, the matrix is said to be &lt;strong&gt;ill-conditioned&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;h3 id=&#34;direct-methods&#34;&gt;Direct Methods&lt;/h3&gt;
&lt;div class=&#34;details admonition Algorithm open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-laptop-code fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Algorithm:	&lt;em&gt;Gaussian Elimination&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;Here&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Algorithm open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-laptop-code fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Algorithm:	&lt;em&gt;Gaussian Elimination with Scaled Partial Pivoting&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;Here&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;$LU$-Decomposition&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;Here&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Theorem open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-list-ul fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Theorem:	&lt;em&gt;$LU$-Decomposition&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;Here&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Cholesky-Decomposition&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;Here&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Algorithm open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-laptop-code fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Algorithm:	&lt;em&gt;Cholesky&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;Here&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;h3 id=&#34;indirect-methods&#34;&gt;Indirect Methods&lt;/h3&gt;
</description>
    </item>
    
    <item>
      <title>Nonlinear Equations</title>
      <link>https://djps.github.io/courses/numericalmethods24/part-1/nonlinear-equations/</link>
      <pubDate>Fri, 17 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://djps.github.io/courses/numericalmethods24/part-1/nonlinear-equations/</guid>
      <description>&lt;p style=&#34;font-size: 14px; letter-spacing: 0.03em; color: rgb(0,0,0,0.54);&#34;&gt; &lt;span style=&#34;font-weight: 700;&#34;&gt; David Sinden &lt;/span&gt; &amp;middot;
&lt;i class=&#34;far fa-calendar&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; March 11, 2024 &amp;middot;
&lt;i class=&#34;far fa-clock&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; 45 minute read &lt;/p&gt;
&lt;h2 id=&#34;root-finding&#34;&gt;Root Finding&lt;/h2&gt;
&lt;h3 id=&#34;bisection-method&#34;&gt;Bisection Method&lt;/h3&gt;
&lt;h3 id=&#34;newtons-method&#34;&gt;Newton&amp;rsquo;s Method&lt;/h3&gt;
&lt;h3 id=&#34;secant-methods&#34;&gt;Secant Methods&lt;/h3&gt;
&lt;h2 id=&#34;convergence&#34;&gt;Convergence&lt;/h2&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;Order of convergence: cubic, quadratic, linear.
Super-linearly, sub-linear,&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Regularity&lt;/th&gt;
&lt;th&gt;Proximity to $r$&lt;/th&gt;
&lt;th&gt;func calls&lt;/th&gt;
&lt;th&gt;Convergence&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Bisection&lt;/td&gt;
&lt;td&gt;$\mathcal{C}^{0}$&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Newton&lt;/td&gt;
&lt;td&gt;$\mathcal{C}^{2}$&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Secant&lt;/td&gt;
&lt;td&gt;$\mathcal{C}^{2}$&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;systems-of-nonlinear-equation&#34;&gt;Systems of Nonlinear Equation&lt;/h2&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Jacobian&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;here.&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Interpolation</title>
      <link>https://djps.github.io/courses/numericalmethods24/part-2/interpolation/</link>
      <pubDate>Fri, 17 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://djps.github.io/courses/numericalmethods24/part-2/interpolation/</guid>
      <description>&lt;p style=&#34;font-size: 14px; letter-spacing: 0.03em; color: rgb(0,0,0,0.54);&#34;&gt; &lt;span style=&#34;font-weight: 700;&#34;&gt; David Sinden &lt;/span&gt; &amp;middot;
&lt;i class=&#34;far fa-calendar&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; March 11, 2024 &amp;middot;
&lt;i class=&#34;far fa-clock&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; 45 minute read &lt;/p&gt;
&lt;h2 id=&#34;interpolation&#34;&gt;Interpolation&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Integration</title>
      <link>https://djps.github.io/courses/numericalmethods24/part-2/integration/</link>
      <pubDate>Fri, 17 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://djps.github.io/courses/numericalmethods24/part-2/integration/</guid>
      <description>&lt;p style=&#34;font-size: 14px; letter-spacing: 0.03em; color: rgb(0,0,0,0.54);&#34;&gt; &lt;span style=&#34;font-weight: 700;&#34;&gt; David Sinden &lt;/span&gt; &amp;middot;
&lt;i class=&#34;far fa-calendar&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; March 11, 2024 &amp;middot;
&lt;i class=&#34;far fa-clock&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; 45 minute read &lt;/p&gt;
&lt;h2 id=&#34;numerical-integration&#34;&gt;Numerical Integration&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Finite Difference Methods for Differential Equations</title>
      <link>https://djps.github.io/courses/numericalmethods24/part-3/odes/</link>
      <pubDate>Fri, 17 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://djps.github.io/courses/numericalmethods24/part-3/odes/</guid>
      <description>&lt;p style=&#34;font-size: 14px; letter-spacing: 0.03em; color: rgb(0,0,0,0.54);&#34;&gt; &lt;span style=&#34;font-weight: 700;&#34;&gt; David Sinden &lt;/span&gt; &amp;middot;
&lt;i class=&#34;far fa-calendar&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; March 11, 2024 &amp;middot;
&lt;i class=&#34;far fa-clock&#34; aria-hidden=&#34;true&#34; style=&#34;color: rgb(0,0,0,0.54);&#34;&gt;&lt;/i&gt; 45 minute read &lt;/p&gt;
&lt;h2 id=&#34;finite-difference-methods-for-differential-equations&#34;&gt;Finite Difference Methods for Differential Equations&lt;/h2&gt;
&lt;p&gt;Solutions are functions.&lt;/p&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Ordinary Differential Equations&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;An &lt;strong&gt;ordinary differential equation&lt;/strong&gt; (ODE) is an equation that involves one of more derivatives of a function of a single variable.&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;!-- For example, with only the first derivative $y^{\prime} \left(t\right) = f\left( y\left(t\right), t)$  --&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Initial Value Problems&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;An &lt;strong&gt;initial value problem&lt;/strong&gt; (IVP) is given by an ordinary differential equation of the form ${y^{\prime} \left(t\right) = f\left( y\left(t\right), t\right)}$ and initial value ${y\left(a\right)=y_a}$ for the unknown function $y\left(t\right)$.&lt;/p&gt;
&lt;p&gt;Often ${a=0}$, so the initial condition reads ${y(0)=y_0}$.&lt;/p&gt;
&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;One step methods&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;A numerical method for approximating the solution to a differential equation is called a &lt;strong&gt;one step method&lt;/strong&gt; if the solution at time step ${i+1}$ depends only on the previous one.&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;h3 id=&#34;forward-euler-method&#34;&gt;Forward Euler Method&lt;/h3&gt;
&lt;h3 id=&#34;backward-euler-method&#34;&gt;Backward Euler Method&lt;/h3&gt;
&lt;h3 id=&#34;heuns-method&#34;&gt;Heun&amp;rsquo;s Method&lt;/h3&gt;
&lt;h3 id=&#34;crank-nicolson-method&#34;&gt;Crank-Nicolson Method&lt;/h3&gt;
&lt;h2 id=&#34;analysis-of-one-step-methods&#34;&gt;Analysis of One-Step Methods&lt;/h2&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;&lt;p&gt;A numerical method is said to be &lt;strong&gt;explicit&lt;/strong&gt; if an approximation $y_{k+1}$ can be calculated directly from already computed values $y_i$, $i&amp;lt;k$. Otherwise, the method is said to be &lt;strong&gt;implicit&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Often, implicit methods require, at each step, the solution of a nonlinear equation for computing $y_{k+1}$.&lt;/p&gt;
&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;A function $f$ is &lt;strong&gt;Holder continuous&lt;/strong&gt; if there exists real constants ${C \gt 0}$ and ${\alpha \le 0}$ such that
$$
\left| f\left(x\right) - f\left(y\right) \right| \le  C \Vert x - y\Vert^\alpha
$$
for all $x$ and $y$. If ${\alpha=1}$ the function is said to be &lt;strong&gt;Lipshitz continuous&lt;/strong&gt;.&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Stable&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;stable&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Consistent&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;consistent&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Order&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;A one-step method is of order $p \in \mathbb{N}$, if for all ${t \in \left[ 0, \tau \right]}$, the solution satisfies the condition that ${\tau\left(h\right) = \mathcal{O}\left( h^p \right) }$ as ${h \rightarrow \infty}$.&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Zero stable &lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Theorem open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-list-ul fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Theorem:	&lt;em&gt;&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;If increment function is Lipshitz continuous for $y_n$ for any $h$ and $t_n$, then the one step method is zero-stable.&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Theorem open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-list-ul fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Theorem:	&lt;em&gt;&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;If increment function is Lipshitz continuous for $y_n$ for any $h$ and $t_{n+1}$ and the method is consistent, then
$$\lim \limits_{h \rightarrow 0} \left| y_n - u_n \right| =0. $$
Also, if the method is of order $p$ and if ${\left| y_0 - u_0 \right| = \mathcal{O}\left(h^p\right)}$ as ${h\rightarrow 0}$, the convergence is of order $p$.&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;div class=&#34;details admonition Definition open&#34;&gt;
        &lt;div class=&#34;details-summary admonition-title&#34;&gt;
            &lt;i class=&#34;icon fas fa-info-circle fa-fw&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;
			Definition:	&lt;em&gt;Absolute Stability&lt;/em&gt;
			
        &lt;/div&gt;
        &lt;div class=&#34;details-content&#34;&gt;
            &lt;div class=&#34;admonition-content&#34;&gt;A numerical scheme for approximating the solution to the linear differential equation $y^{\prime}\left(t\right) = \lambda y\left(t\right)$ with ${\lambda \in \mathbb{C}}$ and initial condition ${y_0 = 1}$ is said to be &lt;strong&gt;absolutely stable&lt;/strong&gt; if $\left|u_n\right| \rightarrow 0$ as $n \rightarrow \infty$, when ${\operatorname{Re}\left(\lambda\right) \lt 0}$, for a fixed value of $h$.&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;h3 id=&#34;runge-kutta-schemes-and-multi-step-schemes&#34;&gt;Runge-Kutta Schemes And Multi-Step Schemes&lt;/h3&gt;
&lt;h2 id=&#34;partial-differential-equations&#34;&gt;Partial Differential Equations&lt;/h2&gt;
</description>
    </item>
    
  </channel>
</rss>
